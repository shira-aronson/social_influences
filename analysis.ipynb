{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aeb0835-6019-412d-b390-628f8cf514ca",
   "metadata": {},
   "source": [
    "This file includes the analysis conducted on the pornography consumption survey data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f7639e-c69d-4024-bb30-e383ab236d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bc5875-147f-4adb-b90b-cf52b13d1738",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f7091e1-e185-4ee4-9ec9-427839b669b0",
   "metadata": {},
   "source": [
    "## Load in and Clean the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf4813f-f2f4-4a3f-85ad-ece2d1628a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and remove non-participant rows clean the dataset\n",
    "data = pd.read_csv(\"\")  # File path can be added here for confidentiality.\n",
    "data = data[~(data['Status'] == \"Survey Preview\")]  # Remove non-participant rows\n",
    "data = data[data['Consent'] == \"I agree to participate in the research\"]  # Keep only rows where participants consented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3ad7d0-a555-4130-835d-9e4ed814eb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the data\n",
    "\n",
    "# Drop unnecessary metadata columns\n",
    "columns_to_drop = [\"UserLanguage\", \"StartDate\", \"EndDate\", \"Status\", \"DistributionChannel\", \n",
    "                   \"Q_RecaptchaScore\", \"Q37_Click.Count\", \"Q38_Click.Count\", \"Q39_Click.Count\", \n",
    "                   \"Q37_Last.Click\", \"Q38_Last.Click\", \"Q39_Last.Click\"]\n",
    "data.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "# Replace empty string entries with NaN for further cleaning\n",
    "data.replace(\"\", np.nan, inplace=True)\n",
    "\n",
    "# Renaming columns\n",
    "rename_dict = {\n",
    "    'Q1': 'age',\n",
    "    'Q2': 'ethnicity',\n",
    "    'Q3_1': 'religious_affiliation',\n",
    "    'Q4': 'education_completed',\n",
    "    'Q5': 'education_region',\n",
    "    'Q6': 'alcohol_per_week',\n",
    "    'Q7': 'gender_identity',\n",
    "    'Q40_1': 'pre_test_feelings',\n",
    "    'Q37_First.Click': 'control_group_start',\n",
    "    'Q37_Page.Submit': 'control_group_end',\n",
    "    'Q38_First.Click': 'info_group_start',\n",
    "    'Q38_Page.Submit': 'info_group_end',\n",
    "    'Q39_First.Click': 'pre_test_start',\n",
    "    'Q39_Page.Submit': 'pre_test_end',\n",
    "    'Q36_1': 'info_group_feelings',\n",
    "    'Q10': 'discomfort_scenario_A',\n",
    "    'Q11': 'discomfort_scenario_B',\n",
    "    'Q12': 'discomfort_scenario_C',\n",
    "    'Q13': 'discomfort_scenario_D',\n",
    "    'Q14': 'discomfort_scenario_E',\n",
    "    'Q15': 'discomfort_scenario_F',\n",
    "    'Q16': 'unclear_scenario_G',\n",
    "    'Q16.1': 'num_partners',\n",
    "    'Q17_1': 'sexual_orientation',\n",
    "    'Q17_1.1': 'frequency_of_sex',\n",
    "    'Q18': 'age_first_exposure',\n",
    "    'Q19_1': 'incident_report',\n",
    "    'Q20': 'relationship_status',\n",
    "    'Q21_1': 'frequency_of_activity_A',\n",
    "    'Q22_1': 'frequency_of_activity_B',\n",
    "    'Q23_1': 'activity_A_without_activity_B',\n",
    "    'Q24_1': 'comfort_discussing_topic_A',\n",
    "    'Q25_1': 'discomfort_discussing_topic_A',\n",
    "    'Q26_1': 'never_discussed_activity_A',\n",
    "    'Q27_1': 'comfort_discussing_activity_B',\n",
    "    'Q28_1': 'activity_B_with_partner',\n",
    "    'Q29_1': 'unaware_activity_B_made',\n",
    "    'Q30_1': 'guilt_feelings',\n",
    "    'Q31_1': 'appeal_level',\n",
    "    'Q32_1': 'awareness_of_creation',\n",
    "    'Q33_1': 'education_about_topic',\n",
    "    'Q34_1': 'friends_comfortable',\n",
    "    'Q35_1': 'people_comfortable'\n",
    "}\n",
    "\n",
    "# Apply renaming\n",
    "data.rename(columns=rename_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6729c307-96a8-4f24-877b-45d1384fdd76",
   "metadata": {},
   "source": [
    "## Look at summary stats for the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc38e07-5da9-419e-8708-6f24b34b9ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store all the results\n",
    "results = {}\n",
    "\n",
    "# Gender distribution\n",
    "gender_counts = data['gender_identity'].value_counts()\n",
    "results['Gender Distribution'] = gender_counts\n",
    "\n",
    "# Race distribution with percentage\n",
    "race_counts = data['ethnicity'].value_counts(normalize=True) * 100\n",
    "race_counts = race_counts.sort_values(ascending=False)\n",
    "results['Race Distribution (%)'] = race_counts\n",
    "\n",
    "# Age distribution: Replacing \"24 or older\" with 24 and converting to numeric\n",
    "data['age'].replace(\"24 or older\", 24, inplace=True)\n",
    "data['age'] = pd.to_numeric(data['age'], errors='coerce')\n",
    "\n",
    "# Summary statistics for age\n",
    "results['Mean Age'] = data['age'].mean()\n",
    "results['Median Age'] = data['age'].median()\n",
    "results['Standard Deviation of Age'] = data['age'].std()\n",
    "results['Minimum Age'] = data['age'].min()\n",
    "results['Maximum Age'] = data['age'].max()\n",
    "\n",
    "# Religious affiliation distribution and summary statistics\n",
    "data['religious_affiliation'] = pd.to_numeric(data['religious_affiliation'], errors='coerce')\n",
    "\n",
    "results['Mean Religious Affiliation'] = data['religious_affiliation'].mean()\n",
    "results['Median Religious Affiliation'] = data['religious_affiliation'].median()\n",
    "results['Standard Deviation of Religious Affiliation'] = data['religious_affiliation'].std()\n",
    "results['Minimum Religious Affiliation'] = data['religious_affiliation'].min()\n",
    "results['Maximum Religious Affiliation'] = data['religious_affiliation'].max()\n",
    "\n",
    "# College completion distribution\n",
    "college_completed_counts = data['education_completed'].value_counts(normalize=True) * 100\n",
    "results['College Completed Distribution (%)'] = college_completed_counts\n",
    "\n",
    "# College region distribution\n",
    "college_region_counts = data['education_region'].value_counts(normalize=True) * 100\n",
    "results['College Region Distribution (%)'] = college_region_counts\n",
    "\n",
    "# Filter data for participants who completed the survey\n",
    "data_complete = data[data['Progress'] == 100]\n",
    "\n",
    "# Sexual orientation distribution\n",
    "sexuality_counts = data_complete['sexual_orientation'].value_counts(normalize=True) * 100\n",
    "results['Sexual Orientation Distribution (%)'] = sexuality_counts\n",
    "\n",
    "# Distribution of missing values in 'sexual_orientation' column by gender\n",
    "na_sexuality = data_complete[data_complete['sexual_orientation'].isna()]\n",
    "na_sexuality_gender_counts = na_sexuality['gender_identity'].value_counts(normalize=True) * 100\n",
    "results['Missing Sexuality by Gender Distribution (%)'] = na_sexuality_gender_counts\n",
    "\n",
    "# Assault history by gender\n",
    "assault_female = data[data['gender_identity'] == 'Cisgender female']['incident_report'].value_counts(normalize=True) * 100\n",
    "assault_male = data[data['gender_identity'] == 'Cisgender male']['incident_report'].value_counts(normalize=True) * 100\n",
    "results['Assault History (Female %)'] = assault_female\n",
    "results['Assault History (Male %)'] = assault_male\n",
    "\n",
    "# Convert results dictionary to DataFrame\n",
    "# Since the lengths of different categories vary, we'll store them in separate DataFrames and write them sequentially to a CSV\n",
    "gender_df = pd.DataFrame(gender_counts).reset_index().rename(columns={'index': 'Gender', 'gender_identity': 'Count'})\n",
    "race_df = pd.DataFrame(race_counts).reset_index().rename(columns={'index': 'Race', 'ethnicity': 'Percentage'})\n",
    "age_stats = pd.DataFrame({\n",
    "    'Statistic': ['Mean Age', 'Median Age', 'Standard Deviation of Age', 'Minimum Age', 'Maximum Age'],\n",
    "    'Value': [results['Mean Age'], results['Median Age'], results['Standard Deviation of Age'], results['Minimum Age'], results['Maximum Age']]\n",
    "})\n",
    "religious_stats = pd.DataFrame({\n",
    "    'Statistic': ['Mean Religious Affiliation', 'Median Religious Affiliation', 'Standard Deviation of Religious Affiliation', 'Minimum Religious Affiliation', 'Maximum Religious Affiliation'],\n",
    "    'Value': [results['Mean Religious Affiliation'], results['Median Religious Affiliation'], results['Standard Deviation of Religious Affiliation'], results['Minimum Religious Affiliation'], results['Maximum Religious Affiliation']]\n",
    "})\n",
    "college_completed_df = pd.DataFrame(college_completed_counts).reset_index().rename(columns={'index': 'Education Completed', 'education_completed': 'Percentage'})\n",
    "college_region_df = pd.DataFrame(college_region_counts).reset_index().rename(columns={'index': 'Education Region', 'education_region': 'Percentage'})\n",
    "sexuality_df = pd.DataFrame(sexuality_counts).reset_index().rename(columns={'index': 'Sexual Orientation', 'sexual_orientation': 'Percentage'})\n",
    "na_sexuality_gender_df = pd.DataFrame(na_sexuality_gender_counts).reset_index().rename(columns={'index': 'Gender', 'gender_identity': 'Missing Sexuality (%)'})\n",
    "assault_female_df = pd.DataFrame(assault_female).reset_index().rename(columns={'index': 'Incident Report', 'incident_report': 'Percentage (Female)'})\n",
    "assault_male_df = pd.DataFrame(assault_male).reset_index().rename(columns={'index': 'Incident Report', 'incident_report': 'Percentage (Male)'})\n",
    "\n",
    "# Write all DataFrames to CSV, appending to the same file\n",
    "with open('survey_summary.csv', 'w') as f:\n",
    "    gender_df.to_csv(f, index=False)\n",
    "    race_df.to_csv(f, index=False)\n",
    "    age_stats.to_csv(f, index=False)\n",
    "    religious_stats.to_csv(f, index=False)\n",
    "    college_completed_df.to_csv(f, index=False)\n",
    "    college_region_df.to_csv(f, index=False)\n",
    "    sexuality_df.to_csv(f, index=False)\n",
    "    na_sexuality_gender_df.to_csv(f, index=False)\n",
    "    assault_female_df.to_csv(f, index=False)\n",
    "    assault_male_df.to_csv(f, index=False)\n",
    "\n",
    "print(\"All results saved to 'survey_summary.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d0d41-59ed-4039-903d-20f50a4e2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trends in sex-related variables\n",
    "\n",
    "# Create an empty dictionary to store all results\n",
    "results = {}\n",
    "\n",
    "# Subset participants who did not report masturbation frequency\n",
    "data_no_mast = data[data['freq_masturbation'].isna()]\n",
    "\n",
    "# Proportion of each gender with no entry in 'freq_masturbation'\n",
    "prop_na_by_gender = data_no_mast['gender_identity'].value_counts(normalize=True) * 100\n",
    "prop_na_by_gender_df = pd.DataFrame(prop_na_by_gender).reset_index().rename(columns={'index': 'Gender', 'gender_identity': 'Percentage of No Entry'})\n",
    "prop_na_by_gender_df.to_csv('proportion_no_entry_freq_masturbation_by_gender.csv', index=False)\n",
    "\n",
    "# Convert 'freq_masturbation' to numeric\n",
    "data['freq_masturbation'] = pd.to_numeric(data['freq_masturbation'], errors='coerce')\n",
    "\n",
    "# Calculate average frequency of masturbation by gender\n",
    "avg_freq_by_gender = data.groupby('gender_identity')['freq_masturbation'].mean()\n",
    "avg_freq_by_gender_df = pd.DataFrame(avg_freq_by_gender).reset_index().rename(columns={'freq_masturbation': 'Average Frequency'})\n",
    "avg_freq_by_gender_df.to_csv('average_freq_masturbation_by_gender.csv', index=False)\n",
    "\n",
    "# Subset data by gender\n",
    "data_female = data[data['gender_identity'] == 'Cisgender female'].copy()\n",
    "data_male = data[data['gender_identity'] == 'Cisgender male'].copy()\n",
    "\n",
    "# Remove rows with missing 'freq_masturbation' values\n",
    "data_male = data_male.dropna(subset=['freq_masturbation'])\n",
    "data_female = data_female.dropna(subset=['freq_masturbation'])\n",
    "\n",
    "# Calculate sample mean and standard error for males\n",
    "sample_mean_male = data_male['freq_masturbation'].mean()\n",
    "se_male = data_male['freq_masturbation'].std() / np.sqrt(len(data_male))\n",
    "\n",
    "# Calculate z-score and p-value for comparison with female sample\n",
    "sample_mean_female = data_female['freq_masturbation'].mean()\n",
    "z_score = (sample_mean_male - sample_mean_female) / se_male\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "\n",
    "z_porn_df = pd.DataFrame({\n",
    "    'Comparison': ['Masturbation Frequency'],\n",
    "    'Z-Score': [z_score],\n",
    "    'P-Value': [p_value]\n",
    "})\n",
    "z_porn_df.to_csv('z_score_p_value_masturbation.csv', index=False)\n",
    "\n",
    "# Create 'in_relationship' column\n",
    "data['in_relationship'] = np.where(data['relationship_status'] == 'Yes', 1, \n",
    "                                   np.where(pd.isna(data['relationship_status']), np.nan, 0))\n",
    "\n",
    "# Calculate average frequency of masturbation by relationship status and gender\n",
    "avg_freq_by_rel_gender = data.groupby(['in_relationship', 'gender_identity'])['freq_masturbation'].mean()\n",
    "avg_freq_by_rel_gender_df = pd.DataFrame(avg_freq_by_rel_gender).reset_index().rename(columns={'freq_masturbation': 'Average Frequency'})\n",
    "avg_freq_by_rel_gender_df.to_csv('average_freq_by_relationship_status_and_gender.csv', index=False)\n",
    "\n",
    "# Group data by 'freq_porn' and calculate percentages\n",
    "freq_porn_distribution = data['freq_porn'].value_counts(normalize=True) * 100\n",
    "freq_porn_distribution_df = pd.DataFrame(freq_porn_distribution).reset_index().rename(columns={'index': 'Porn Frequency', 'freq_porn': 'Percentage'})\n",
    "freq_porn_distribution_df.to_csv('porn_frequency_distribution.csv', index=False)\n",
    "\n",
    "# Remove rows with missing 'freq_porn'\n",
    "data_male = data_male.dropna(subset=['freq_porn'])\n",
    "data_female = data_female.dropna(subset=['freq_porn'])\n",
    "\n",
    "# Calculate sample mean and standard error for 'freq_porn' in males\n",
    "sample_mean_porn_male = data_male['freq_porn'].mean()\n",
    "se_porn_male = data_male['freq_porn'].std() / np.sqrt(len(data_male))\n",
    "\n",
    "# Calculate z-score and p-value for comparison with female sample\n",
    "sample_mean_porn_female = data_female['freq_porn'].mean()\n",
    "z_score_porn = (sample_mean_porn_male - sample_mean_porn_female) / se_porn_male\n",
    "p_value_porn = 2 * (1 - stats.norm.cdf(abs(z_score_porn)))\n",
    "\n",
    "z_porn_df = pd.DataFrame({\n",
    "    'Comparison': ['Porn Frequency'],\n",
    "    'Z-Score': [z_score_porn],\n",
    "    'P-Value': [p_value_porn]\n",
    "})\n",
    "z_porn_df.to_csv('z_score_p_value_porn.csv', index=False)\n",
    "\n",
    "# Convert 'freq_sex' to numeric and calculate correlations\n",
    "data['freq_sex'] = pd.to_numeric(data['freq_sex'], errors='coerce')\n",
    "\n",
    "# Male correlation between 'freq_sex' and 'freq_masturbation'\n",
    "male_corr = data_male[['freq_sex', 'freq_masturbation']].dropna().corr().loc['freq_sex', 'freq_masturbation']\n",
    "male_corr_df = pd.DataFrame({'Male Correlation (freq_sex and freq_masturbation)': [male_corr]})\n",
    "male_corr_df.to_csv('male_correlation_freq_sex_freq_masturbation.csv', index=False)\n",
    "\n",
    "# Female correlation between 'freq_sex' and 'freq_porn'\n",
    "female_corr = data_female[['freq_sex', 'freq_porn']].dropna().corr().loc['freq_sex', 'freq_porn']\n",
    "female_corr_df = pd.DataFrame({'Female Correlation (freq_sex and freq_porn)': [female_corr]})\n",
    "female_corr_df.to_csv('female_correlation_freq_sex_freq_porn.csv', index=False)\n",
    "\n",
    "# Correlation between 'freq_porn' and 'freq_masturbation' across all participants\n",
    "data_complete_porn = data.dropna(subset=['freq_porn', 'freq_masturbation'])\n",
    "porn_mast_corr = data_complete_porn[['freq_porn', 'freq_masturbation']].corr().loc['freq_porn', 'freq_masturbation']\n",
    "porn_mast_corr_df = pd.DataFrame({'Correlation between freq_porn and freq_masturbation': [porn_mast_corr]})\n",
    "porn_mast_corr_df.to_csv('correlation_freq_porn_freq_masturbation.csv', index=False)\n",
    "\n",
    "# Analyze 'mast_no_porn' column\n",
    "data_complete_mast_no_porn = data.dropna(subset=['mast_no_porn'])\n",
    "data_complete_mast_no_porn['mast_no_porn'] = pd.to_numeric(data_complete_mast_no_porn['mast_no_porn'], errors='coerce')\n",
    "mast_no_porn_summary_df = data_complete_mast_no_porn['mast_no_porn'].describe()\n",
    "mast_no_porn_summary_df.to_csv('mast_no_porn_summary.csv', index=False)\n",
    "\n",
    "print(\"All results saved to CSV files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8193cde8-75a2-467c-80f0-8dbc24d93668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age when participants first viewed adult material\n",
    "age_viewed_distribution = data['age_first_exposure'].value_counts(normalize=True) * 100\n",
    "age_viewed_distribution.sort_values(ascending=False).to_csv('age_viewed_distribution.csv')\n",
    "\n",
    "# Convert 'speak_sex' to numeric and filter out rows with missing values\n",
    "data['speak_sex'] = pd.to_numeric(data['speak_sex'], errors='coerce')\n",
    "data_speak_sex = data.dropna(subset=['speak_sex'])\n",
    "speak_sex_distribution = data_speak_sex['speak_sex'].value_counts(normalize=True) * 100\n",
    "speak_sex_distribution.to_csv('speak_sex_distribution.csv')\n",
    "\n",
    "# Convert 'speak_porn' to numeric and filter out rows with missing values\n",
    "data['speak_porn'] = pd.to_numeric(data['speak_porn'], errors='coerce')\n",
    "data_speak_porn = data.dropna(subset=['speak_porn'])\n",
    "speak_porn_distribution = data_speak_porn['speak_porn'].value_counts(normalize=True) * 100\n",
    "speak_porn_distribution.to_csv('speak_porn_distribution.csv')\n",
    "\n",
    "# Convert 'porn_partner' to numeric and filter out rows with missing values\n",
    "data['porn_partner'] = pd.to_numeric(data['porn_partner'], errors='coerce')\n",
    "data_porn_partner = data.dropna(subset=['porn_partner'])\n",
    "porn_partner_distribution = data_porn_partner['porn_partner'].value_counts(normalize=True) * 100\n",
    "porn_partner_distribution.to_csv('porn_partner_distribution.csv')\n",
    "\n",
    "# Subset data by gender for 'porn_partner'\n",
    "data_male_partner = data_porn_partner[data_porn_partner['gender_identity'] == 'Cisgender male']\n",
    "data_female_partner = data_porn_partner[data_porn_partner['gender_identity'] == 'Cisgender female']\n",
    "\n",
    "data_male_partner['porn_partner'].describe().to_csv('porn_partner_summary_male.csv')\n",
    "data_female_partner['porn_partner'].describe().to_csv('porn_partner_summary_female.csv')\n",
    "\n",
    "# Convert 'never_speak_mast' to numeric and filter out rows with missing values\n",
    "data['never_speak_mast'] = pd.to_numeric(data['never_speak_mast'], errors='coerce')\n",
    "data_never_speak_mast = data.dropna(subset=['never_speak_mast'])\n",
    "never_speak_mast_distribution = data_never_speak_mast['never_speak_mast'].value_counts(normalize=True) * 100\n",
    "never_speak_mast_distribution.to_csv('never_speak_mast_distribution.csv')\n",
    "\n",
    "# Convert 'educ_sex' to numeric and filter out rows with missing values\n",
    "data['educ_sex'] = pd.to_numeric(data['educ_sex'], errors='coerce')\n",
    "data_educ_sex = data.dropna(subset=['educ_sex'])\n",
    "educ_sex_distribution = data_educ_sex['educ_sex'].value_counts(normalize=True) * 100\n",
    "educ_sex_distribution.to_csv('educ_sex_distribution.csv')\n",
    "\n",
    "# Subset data by gender for 'educ_sex'\n",
    "data_male_educ = data_educ_sex[data_educ_sex['gender_identity'] == 'Cisgender male']\n",
    "data_female_educ = data_educ_sex[data_educ_sex['gender_identity'] == 'Cisgender female']\n",
    "\n",
    "data_male_educ['educ_sex'].describe().to_csv('educ_sex_summary_male.csv')\n",
    "data_female_educ['educ_sex'].describe().to_csv('educ_sex_summary_female.csv')\n",
    "\n",
    "# Calculate z-score and p-value for 'educ_sex'\n",
    "sample_mean_male_educ = data_male_educ['educ_sex'].mean()\n",
    "se_male_educ = data_male_educ['educ_sex'].std() / np.sqrt(len(data_male_educ))\n",
    "sample_mean_female_educ = data_female_educ['educ_sex'].mean()\n",
    "z_score_educ = (sample_mean_male_educ - sample_mean_female_educ) / se_male_educ\n",
    "p_value_educ = 2 * (1 - stats.norm.cdf(abs(z_score_educ)))\n",
    "\n",
    "z_score_educ_df = pd.DataFrame({'Z-Score': [z_score_educ], 'P-Value': [p_value_educ]})\n",
    "z_score_educ_df.to_csv('z_score_p_value_educ_sex.csv')\n",
    "\n",
    "# Trends in finding pornography appealing\n",
    "data['appeals'] = pd.to_numeric(data['appeals'], errors='coerce')\n",
    "data_appeals = data.dropna(subset=['appeals'])\n",
    "appeals_distribution = data_appeals['appeals'].value_counts(normalize=True) * 100\n",
    "appeals_distribution.sort_values(ascending=False).to_csv('appeals_distribution.csv')\n",
    "\n",
    "# Subset data by gender for 'appeals'\n",
    "data_male_appeals = data_appeals[data_appeals['gender_identity'] == 'Cisgender male']\n",
    "data_female_appeals = data_appeals[data_appeals['gender_identity'] == 'Cisgender female']\n",
    "\n",
    "data_male_appeals['appeals'].describe().to_csv('appeals_summary_male.csv')\n",
    "data_female_appeals['appeals'].describe().to_csv('appeals_summary_female.csv')\n",
    "\n",
    "# Calculate z-score and p-value for 'appeals'\n",
    "sample_mean_male_appeals = data_male_appeals['appeals'].mean()\n",
    "se_male_appeals = data_male_appeals['appeals'].std() / np.sqrt(len(data_male_appeals))\n",
    "sample_mean_female_appeals = data_female_appeals['appeals'].mean()\n",
    "z_score_appeals = (sample_mean_male_appeals - sample_mean_female_appeals) / se_male_appeals\n",
    "p_value_appeals = 2 * (1 - stats.norm.cdf(abs(z_score_appeals)))\n",
    "\n",
    "z_score_appeals_df = pd.DataFrame({'Z-Score': [z_score_appeals], 'P-Value': [p_value_appeals]})\n",
    "z_score_appeals_df.to_csv('z_score_p_value_appeals.csv')\n",
    "\n",
    "# Knowledge and attitudes around pornography\n",
    "data['dont_know_porn_made'] = pd.to_numeric(data['dont_know_porn_made'], errors='coerce')\n",
    "data_dont_know = data.dropna(subset=['dont_know_porn_made'])\n",
    "dont_know_distribution = data_dont_know['dont_know_porn_made'].value_counts(normalize=True) * 100\n",
    "dont_know_distribution.to_csv('dont_know_porn_made_distribution.csv')\n",
    "\n",
    "# Subset data by gender for 'dont_know_porn_made'\n",
    "data_male_dont_know = data_dont_know[data_dont_know['gender_identity'] == 'Cisgender male']\n",
    "data_female_dont_know = data_dont_know[data_dont_know['gender_identity'] == 'Cisgender female']\n",
    "\n",
    "data_male_dont_know['dont_know_porn_made'].describe().to_csv('dont_know_porn_made_summary_male.csv')\n",
    "data_female_dont_know['dont_know_porn_made'].describe().to_csv('dont_know_porn_made_summary_female.csv')\n",
    "\n",
    "# Calculate z-score and p-value for 'dont_know_porn_made'\n",
    "sample_mean_male_dont_know = data_male_dont_know['dont_know_porn_made'].mean()\n",
    "se_male_dont_know = data_male_dont_know['dont_know_porn_made'].std() / np.sqrt(len(data_male_dont_know))\n",
    "sample_mean_female_dont_know = data_female_dont_know['dont_know_porn_made'].mean()\n",
    "z_score_dont_know = (sample_mean_male_dont_know - sample_mean_female_dont_know) / se_male_dont_know\n",
    "p_value_dont_know = 2 * (1 - stats.norm.cdf(abs(z_score_dont_know)))\n",
    "\n",
    "z_score_dont_know_df = pd.DataFrame({'Z-Score': [z_score_dont_know], 'P-Value': [p_value_dont_know]})\n",
    "z_score_dont_know_df.to_csv('z_score_p_value_dont_know_porn_made.csv')\n",
    "\n",
    "# Guilt feelings around pornography\n",
    "data['guilt_feelings'] = pd.to_numeric(data['guilt_feelings'], errors='coerce')\n",
    "data_guilt = data.dropna(subset=['guilt_feelings'])\n",
    "guilt_distribution = data_guilt['guilt_feelings'].value_counts(normalize=True) * 100\n",
    "guilt_distribution.to_csv('guilt_feelings_distribution.csv')\n",
    "\n",
    "# Subset data by gender for 'guilt_feelings'\n",
    "data_male_guilt = data_guilt[data_guilt['gender_identity'] == 'Cisgender male']\n",
    "data_female_guilt = data_guilt[data_guilt['gender_identity'] == 'Cisgender female']\n",
    "\n",
    "data_male_guilt['guilt_feelings'].describe().to_csv('guilt_feelings_summary_male.csv')\n",
    "data_female_guilt['guilt_feelings'].describe().to_csv('guilt_feelings_summary_female.csv')\n",
    "\n",
    "# Calculate z-score and p-value for 'guilt_feelings'\n",
    "sample_mean_male_guilt = data_male_guilt['guilt_feelings'].mean()\n",
    "se_male_guilt = data_male_guilt['guilt_feelings'].std() / np.sqrt(len(data_male_guilt))\n",
    "sample_mean_female_guilt = data_female_guilt['guilt_feelings'].mean()\n",
    "z_score_guilt = (sample_mean_male_guilt - sample_mean_female_guilt) / se_male_guilt\n",
    "p_value_guilt = 2 * (1 - stats.norm.cdf(abs(z_score_guilt)))\n",
    "\n",
    "z_score_guilt_df = pd.DataFrame({'Z-Score': [z_score_guilt], 'P-Value': [p_value_guilt]})\n",
    "z_score_guilt_df.to_csv('z_score_p_value_guilt_feelings.csv')\n",
    "\n",
    "# Uncomfortable speaking about sex\n",
    "data['uncomfy_speak_sex'] = pd.to_numeric(data['uncomfy_speak_sex'], errors='coerce')\n",
    "data_uncomfy_speak_sex = data.dropna(subset=['uncomfy_speak_sex'])\n",
    "uncomfy_speak_sex_distribution = data_uncomfy_speak_sex['uncomfy_speak_sex'].value_counts(normalize=True) * 100\n",
    "uncomfy_speak_sex_distribution.to_csv('uncomfy_speak_sex_distribution.csv')\n",
    "\n",
    "# Friends and people comfortable scores\n",
    "data['friends_comfortable'] = pd.to_numeric(data['friends_comfortable'], errors='coerce')\n",
    "data['people_comfortable'] = pd.to_numeric(data['people_comfortable'], errors='coerce')\n",
    "\n",
    "data_friends_ppl_okay = data.dropna(subset=['friends_comfortable', 'people_comfortable'])\n",
    "friends_distribution = data_friends_ppl_okay['friends_comfortable'].value_counts(normalize=True) * 100\n",
    "people_distribution = data_friends_ppl_okay['people_comfortable'].value_counts(normalize=True) * 100\n",
    "\n",
    "friends_distribution.to_csv('friends_comfortable_distribution.csv')\n",
    "people_distribution.to_csv('people_comfortable_distribution.csv')\n",
    "\n",
    "# Correlation between 'friends_comfortable' and 'people_comfortable'\n",
    "correlation_friends_ppl_okay = data_friends_ppl_okay[['friends_comfortable', 'people_comfortable']].corr().loc['friends_comfortable', 'people_comfortable']\n",
    "pd.DataFrame({'Correlation': [correlation_friends_ppl_okay]}).to_csv('correlation_friends_people_comfortable.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb135578-526e-4c79-a107-aab02d511560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a1325f8a-fd32-4e3a-907e-10949fb65671",
   "metadata": {},
   "source": [
    "## Comfort Level Overall\n",
    "\n",
    "In the experiment, participants in the control and treatment groups describe their comfort with a variety of sexually-explicit vignettes. Some vignettes describe consensual scenarios, while others are non-consensual or unclear. In the following section, I plot the overall comfort level for each scenario, grouped by consent level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b45764-2de8-4d75-bb21-51ffa70856fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate comfort level in non-consensual scenarios.\n",
    "\n",
    "# Define a function to plot comfort levels and save to PDF\n",
    "def plot_comfort_levels(column, title, filename):\n",
    "    # Count the values for the given column and fill missing categories with 0\n",
    "    counts = data[column].value_counts().reindex(\n",
    "        [\"Very uncomfortable\", \"Uncomfortable\", \"Neither comfortable nor uncomfortable\", \n",
    "         \"Comfortable\", \"Very comfortable\"], fill_value=0)\n",
    "\n",
    "    # Create the plot\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.barplot(x=counts.index, y=counts.values)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Comfort Level\")\n",
    "    plt.ylabel(\"Number of Responses\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot as a PDF file\n",
    "    pdf_filename = f\"{filename}.pdf\"\n",
    "    plt.savefig(pdf_filename)\n",
    "    print(f\"Saved: {pdf_filename}\")\n",
    "    plt.close()\n",
    "\n",
    "# List of columns, their corresponding titles, and filenames for PDFs\n",
    "scenarios = [\n",
    "    ('discomfort_scenario_A', 'Aggregate Comfort Level with Non-Consensual Scenario A', 'non_consent_scenario_A_comfort_level'),\n",
    "    ('discomfort_scenario_F', 'Aggregate Comfort Level with Non-Consensual Scenario F', 'non_consent_scenario_F_comfort_level'),\n",
    "    ('discomfort_scenario_E', 'Aggregate Comfort Level with Non-Consensual Scenario E', 'non_consent_scenario_E_comfort_level')\n",
    "]\n",
    "\n",
    "# Loop through each scenario, plot, and save as PDF\n",
    "for column, title, filename in scenarios:\n",
    "    plot_comfort_levels(column, title, filename)\n",
    "\n",
    "# Combined plot of comfort levels in non-consensual scenarios\n",
    "\n",
    "# Import GridSpec for arranging plots in a grid\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "# Create a function to plot multiple scenarios in one figure\n",
    "def combined_plot_scenarios():\n",
    "    # Create subplots with GridSpec\n",
    "    fig = plt.figure(figsize=(18, 6))\n",
    "    grid = GridSpec(1, 3, figure=fig)\n",
    "\n",
    "    # Plot for Scenario A\n",
    "    ax1 = fig.add_subplot(grid[0, 0])\n",
    "    counts_scenario_A = data['discomfort_scenario_A'].value_counts().reindex(\n",
    "        [\"Very uncomfortable\", \"Uncomfortable\", \"Neither comfortable nor uncomfortable\", \n",
    "         \"Comfortable\", \"Very comfortable\"], fill_value=0)\n",
    "    sns.barplot(x=counts_scenario_A.index, y=counts_scenario_A.values, ax=ax1)\n",
    "    ax1.set_title('a. Scenario A')\n",
    "    ax1.set_xlabel('Comfort Level')\n",
    "    ax1.set_ylabel('Number of Responses')\n",
    "    ax1.set_xticklabels(counts_scenario_A.index, rotation=45)\n",
    "\n",
    "    # Plot for Scenario F\n",
    "    ax2 = fig.add_subplot(grid[0, 1])\n",
    "    counts_scenario_F = data['discomfort_scenario_F'].value_counts().reindex(\n",
    "        [\"Very uncomfortable\", \"Uncomfortable\", \"Neither comfortable nor uncomfortable\", \n",
    "         \"Comfortable\", \"Very comfortable\"], fill_value=0)\n",
    "    sns.barplot(x=counts_scenario_F.index, y=counts_scenario_F.values, ax=ax2)\n",
    "    ax2.set_title('b. Scenario F')\n",
    "    ax2.set_xlabel('Comfort Level')\n",
    "    ax2.set_ylabel('')\n",
    "    ax2.set_xticklabels(counts_scenario_F.index, rotation=45)\n",
    "\n",
    "    # Plot for Scenario E\n",
    "    ax3 = fig.add_subplot(grid[0, 2])\n",
    "    counts_scenario_E = data['discomfort_scenario_E'].value_counts().reindex(\n",
    "        [\"Very uncomfortable\", \"Uncomfortable\", \"Neither comfortable nor uncomfortable\", \n",
    "         \"Comfortable\", \"Very comfortable\"], fill_value=0)\n",
    "    sns.barplot(x=counts_scenario_E.index, y=counts_scenario_E.values, ax=ax3)\n",
    "    ax3.set_title('c. Scenario E')\n",
    "    ax3.set_xlabel('Comfort Level')\n",
    "    ax3.set_ylabel('')\n",
    "    ax3.set_xticklabels(counts_scenario_E.index, rotation=45)\n",
    "\n",
    "    # Add a title to the overall figure\n",
    "    fig.suptitle(\"Figure 2: Comfort with Non-Consensual Scenarios\", fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Save the combined plot as a PDF\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to fit title\n",
    "    plt.savefig(\"combined_non_consent_scenarios.pdf\")\n",
    "    print(\"Saved: combined_non_consent_scenarios.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to generate and save the combined plot\n",
    "combined_plot_scenarios()\n",
    "\n",
    "#repeat plotting for consensual scenarios.\n",
    "\n",
    "# Function to create bar plot for each scenario\n",
    "def plot_comfort_scenario(data, column, title, ax):\n",
    "    # Create a target order for the comfort levels\n",
    "    target_order = [\"Very uncomfortable\", \"Uncomfortable\", \"Neither comfortable nor uncomfortable\", \n",
    "                    \"Comfortable\", \"Very comfortable\"]\n",
    "    \n",
    "    # Count the values for each comfort level, filling missing categories with 0\n",
    "    counts = data[column].value_counts().reindex(target_order, fill_value=0)\n",
    "    \n",
    "    # Create the bar plot on the given axis\n",
    "    sns.barplot(x=counts.index, y=counts.values, ax=ax)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Comfort Level')\n",
    "    ax.set_ylabel('Number of Responses')\n",
    "    ax.set_xticklabels(counts.index, rotation=45)\n",
    "\n",
    "# Set up the figure and GridSpec for arranging plots\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "grid = GridSpec(1, 3, figure=fig)\n",
    "\n",
    "# Plot for Scenario Sam (consensual)\n",
    "ax1 = fig.add_subplot(grid[0, 0])\n",
    "plot_comfort_scenario(data, 'comfort_scenario_Sam', 'Aggregate Comfort Level with Consensual Scenario (Sam)', ax1)\n",
    "\n",
    "# Plot for Scenario Dan\n",
    "ax2 = fig.add_subplot(grid[0, 1])\n",
    "plot_comfort_scenario(data, 'comfort_scenario_Dan', 'Aggregate Comfort Level with Consensual Scenario (Dan)', ax2)\n",
    "\n",
    "# Plot for Scenario Rebecca\n",
    "ax3 = fig.add_subplot(grid[0, 2])\n",
    "plot_comfort_scenario(data, 'comfort_scenario_Rebecca', 'Aggregate Comfort Level with Consensual Scenario (Rebecca)', ax3)\n",
    "\n",
    "# Set the overall title for the figure\n",
    "fig.suptitle(\"Figure 3: Comfort with Consensual Scenarios\", fontsize=16, fontweight='bold')\n",
    "\n",
    "# Save the combined plot as a PDF\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to fit title\n",
    "plt.savefig(\"combined_consent_scenarios.pdf\")\n",
    "plt.show()\n",
    "\n",
    "#recreate above plot with small tweaks\n",
    "\n",
    "# Filter out rows with NaNs\n",
    "data_filtered_sam = data[~data['comfort_scenario_Sam'].isna()]\n",
    "data_filtered_dan = data[~data['comfort_scenario_Dan'].isna()]\n",
    "data_filtered_rebecca = data[~data['comfort_scenario_Rebecca'].isna()]\n",
    "\n",
    "# Function to create filtered bar plots\n",
    "def plot_filtered_scenario(data, column, title, ax):\n",
    "    # Create a target order for the comfort levels\n",
    "    target_order = [\"Very uncomfortable\", \"Uncomfortable\", \"Neither comfortable nor uncomfortable\", \n",
    "                    \"Comfortable\", \"Very comfortable\"]\n",
    "    \n",
    "    # Count the values for each comfort level, filling missing categories with 0\n",
    "    counts = data[column].value_counts().reindex(target_order, fill_value=0)\n",
    "    \n",
    "    # Create the bar plot on the given axis\n",
    "    sns.barplot(x=counts.index, y=counts.values, ax=ax, color=\"black\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticklabels(['VU', 'U', 'N', 'C', 'VC'], rotation=45)\n",
    "    ax.set_ylabel('Number of Responses')\n",
    "\n",
    "# Set up the figure and GridSpec for arranging plots\n",
    "fig = plt.figure(figsize=(18, 6))\n",
    "grid = GridSpec(1, 3, figure=fig)\n",
    "\n",
    "# Plot for Scenario Sam\n",
    "ax1 = fig.add_subplot(grid[0, 0])\n",
    "plot_filtered_scenario(data_filtered_sam, 'comfort_scenario_Sam', 'a. Sam', ax1)\n",
    "\n",
    "# Plot for Scenario Dan\n",
    "ax2 = fig.add_subplot(grid[0, 1])\n",
    "plot_filtered_scenario(data_filtered_dan, 'comfort_scenario_Dan', 'b. Dan', ax2)\n",
    "ax2.set_ylabel('')\n",
    "\n",
    "# Plot for Scenario Rebecca\n",
    "ax3 = fig.add_subplot(grid[0, 2])\n",
    "plot_filtered_scenario(data_filtered_rebecca, 'comfort_scenario_Rebecca', 'c. Rebecca', ax3)\n",
    "ax3.set_ylabel('')\n",
    "\n",
    "# Set overall layout and title\n",
    "plt.tight_layout()\n",
    "fig.suptitle(\"Comfort with Consensual Scenarios\", fontsize=16, fontweight='bold', y=1.02)\n",
    "plt.subplots_adjust(top=0.88)\n",
    "\n",
    "# Save the plot as a PDF\n",
    "plt.savefig(\"filtered_consent_scenarios.pdf\")\n",
    "plt.show()\n",
    "\n",
    "#redo plotting where consent is unclear\n",
    "\n",
    "# Filter out missing values in the 'unclear_scenario_G' column\n",
    "data_filtered_max = data[~data['unclear_scenario_G'].isna()]\n",
    "\n",
    "# Function to create bar plots for specific scenarios\n",
    "def plot_unclear_scenario(data, column, ax):\n",
    "    # Create a target order for the comfort levels\n",
    "    target_order = [\"Very uncomfortable\", \"Uncomfortable\", \"Neither comfortable nor uncomfortable\", \n",
    "                    \"Comfortable\", \"Very comfortable\"]\n",
    "    \n",
    "    # Count the values for each comfort level, filling missing categories with 0\n",
    "    counts = data[column].value_counts().reindex(target_order, fill_value=0)\n",
    "    \n",
    "    # Create the bar plot\n",
    "    sns.barplot(x=counts.index, y=counts.values, ax=ax, color=\"black\")\n",
    "    ax.set_xticklabels(['VU', 'U', 'N', 'C', 'VC'], rotation=45)\n",
    "    ax.set_ylabel('Number of Responses')\n",
    "\n",
    "# Set up the figure and GridSpec for arranging plots\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "grid = GridSpec(1, 2, figure=fig)\n",
    "\n",
    "# Plot for unclear scenario\n",
    "ax1 = fig.add_subplot(grid[0, 0])\n",
    "plot_unclear_scenario(data_filtered_max, 'unclear_scenario_G', ax1)\n",
    "ax1.set_title(\"Unclear Scenario\")\n",
    "ax1.set_xlabel(None)\n",
    "ax1.set_ylabel(\"Number of Responses\")\n",
    "\n",
    "# Plot for Scenario Rebecca (from previous work)\n",
    "ax2 = fig.add_subplot(grid[0, 1])\n",
    "plot_unclear_scenario(data_filtered_rebecca, 'comfort_scenario_Rebecca', ax2)\n",
    "ax2.set_title(\"Rebecca\")\n",
    "ax2.set_ylabel(None)\n",
    "\n",
    "# Set the overall layout and save the plot\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.88)\n",
    "\n",
    "# Save the combined plot as a PDF\n",
    "plt.savefig(\"unclear_and_rebecca_scenarios.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca2ffca-9e18-4730-b9c0-4d7dac1487e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d6b9b49-4566-4537-bf2c-e0e60bb42058",
   "metadata": {},
   "source": [
    "## Diving Further into Responses to Individual Vignettes\n",
    "Some vignettes describe situations involving heterosexual partners, while some involve stituations describe homosexual partners. Level of comfort among participants may be related to whether the scenario described aligns with their sexual preference. Here, I investigate differences in comfort level between gay and straight women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95c9473-4eaf-4bd3-b728-ea9e78267314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for Cisgender female participants\n",
    "data_female = data[data['gender_identity'] == 'Cisgender female'].copy()\n",
    "\n",
    "# Convert sexual_orientation to numeric\n",
    "data_female['sexual_orientation'] = pd.to_numeric(data_female['sexual_orientation'], errors='coerce')\n",
    "\n",
    "# Create a lookup dictionary to map comfort levels to numeric values\n",
    "comfort_lookup = {\n",
    "    \"Very uncomfortable\": 1,\n",
    "    \"Uncomfortable\": 2,\n",
    "    \"Neither comfortable nor uncomfortable\": 3,\n",
    "    \"Comfortable\": 4,\n",
    "    \"Very comfortable\": 5\n",
    "}\n",
    "\n",
    "# Use the lookup table to replace string values with numeric values for specific columns\n",
    "data_female['discomfort_scenario_F'] = data_female['discomfort_scenario_F'].map(comfort_lookup)\n",
    "data_female['discomfort_scenario_E'] = data_female['discomfort_scenario_E'].map(comfort_lookup)\n",
    "\n",
    "# Subset participants into two groups based on sexual orientation\n",
    "group_homosexual = data_female[data_female['sexual_orientation'] >= 3].copy()\n",
    "group_heterosexual = data_female[data_female['sexual_orientation'] < 3].copy()\n",
    "\n",
    "# Drop NaN values in 'discomfort_scenario_F' for both groups\n",
    "group_homosexual = group_homosexual.dropna(subset=['discomfort_scenario_F'])\n",
    "group_heterosexual = group_heterosexual.dropna(subset=['discomfort_scenario_F'])\n",
    "\n",
    "# Calculate summary statistics for both groups\n",
    "summary_homosexual = group_homosexual['discomfort_scenario_F'].describe()\n",
    "summary_heterosexual = group_heterosexual['discomfort_scenario_F'].describe()\n",
    "\n",
    "# Calculate the sample mean and standard error for 'discomfort_scenario_F' in the homosexual group\n",
    "sample_mean_homosexual = group_homosexual['discomfort_scenario_F'].mean()\n",
    "se_homosexual = group_homosexual['discomfort_scenario_F'].std() / np.sqrt(len(group_homosexual))\n",
    "\n",
    "# Calculate the mean for 'discomfort_scenario_F' in the heterosexual group\n",
    "mean_heterosexual = group_heterosexual['discomfort_scenario_F'].mean()\n",
    "\n",
    "# Calculate the z-score and p-value for the difference in means between the two groups\n",
    "z_score = (sample_mean_homosexual - mean_heterosexual) / se_homosexual\n",
    "p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = pd.DataFrame({\n",
    "    'Group': ['Homosexual', 'Heterosexual'],\n",
    "    'Mean_Discomfort_Scenario_F': [sample_mean_homosexual, mean_heterosexual],\n",
    "    'Standard_Error': [se_homosexual, 'N/A'], \n",
    "    'Z-Score': [z_score, 'N/A'],  \n",
    "    'P-Value': [p_value, 'N/A']  \n",
    "})\n",
    "\n",
    "# Save summary statistics and results to CSV\n",
    "summary_stats = pd.concat([summary_homosexual, summary_heterosexual], axis=1)\n",
    "summary_stats.columns = ['Homosexual', 'Heterosexual']\n",
    "\n",
    "# Save the results to CSV files\n",
    "summary_stats.to_csv('summary_statistics.csv')\n",
    "results.to_csv('results_comparison.csv', index=False)\n",
    "\n",
    "print(\"Summary statistics and comparison results saved as CSV files.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71adff1-0a2e-4cd8-aa82-9fbf4c2c5d16",
   "metadata": {},
   "source": [
    "Relatedly, participants may feel uncomfortable in reading about scenarios that don't align with their sexual preference. To address this concern, I restrict to participants who completed the experiment, and then compared the number of questions skipped between straight and gay women."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ccff3d-67d6-4db4-a9ae-49dbba1f1d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out rows where Progress is 100%\n",
    "data_complete = data[data['Progress'] == 100]\n",
    "\n",
    "# Subset for Cisgender female participants\n",
    "data_female_complete = data_complete[data_complete['gender_identity'] == 'Cisgender female']\n",
    "\n",
    "# Subset for homosexual (sexual_orientation >= 3) and heterosexual (sexual_orientation < 3) groups\n",
    "group_homosexual = data_female_complete[data_female_complete['sexual_orientation'] >= 3]\n",
    "group_heterosexual = data_female_complete[data_female_complete['sexual_orientation'] < 3]\n",
    "\n",
    "# List of columns to check for missing values (NaNs)\n",
    "cols_to_check = [\"discomfort_scenario_A\", \"discomfort_scenario_F\", \"discomfort_scenario_E\", \n",
    "                 \"discomfort_scenario_B\", \"discomfort_scenario_C\", \"discomfort_scenario_D\", \"unclear_scenario_G\"]\n",
    "\n",
    "# Calculate the proportion of NaN values for each column in both subsets\n",
    "prop_na_homosexual = group_homosexual[cols_to_check].isna().mean()\n",
    "prop_na_heterosexual = group_heterosexual[cols_to_check].isna().mean()\n",
    "\n",
    "# Create a DataFrame to compare the proportions\n",
    "prop_na_df = pd.DataFrame({\n",
    "    'category': cols_to_check,\n",
    "    'homosexual_prop_na': prop_na_homosexual.values,\n",
    "    'heterosexual_prop_na': prop_na_heterosexual.values\n",
    "})\n",
    "\n",
    "# Save the proportions to a CSV file\n",
    "prop_na_df.to_csv('non_answering_rates.csv', index=False)\n",
    "\n",
    "print(\"Proportions of non-answering participants saved to 'non_answering_rates.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f5d2e9-46ad-4b92-ab17-2cee7ee3e100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45125d54-6ad8-41c7-9864-6ed506cdd4c9",
   "metadata": {},
   "source": [
    "## Comparing the Control and Treatment Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ebaf11-92e5-4ed5-90de-dc17e989d261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify groups\n",
    "\n",
    "# Assign participant group based on the conditions\n",
    "data['group_number'] = np.nan  # Add a new column 'group_number' initialized with NaN\n",
    "\n",
    "# Assign values to 'group_number' based on conditions\n",
    "data['group_number'] = np.where(data['info_group_start'].notna(), 'info', data['group_number'])\n",
    "data['group_number'] = np.where(data['pre_test_start'].notna(), 'pressure', data['group_number'])\n",
    "\n",
    "# For any remaining NaN values, assign 'control' group\n",
    "data['group_number'].fillna('control', inplace=True)\n",
    "\n",
    "# Verify the assignment\n",
    "print(data['group_number'].value_counts())\n",
    "\n",
    "# Convert end and start times to numeric by replacing commas with dots and converting to float\n",
    "columns_to_convert = ['info_group_end', 'info_group_start', 'pre_test_end', 'pre_test_start']\n",
    "for column in columns_to_convert:\n",
    "    data[column] = data[column].str.replace(\",\", \".\").astype(float)\n",
    "\n",
    "# Verify the conversions\n",
    "print(data[['info_group_end', 'info_group_start', 'pre_test_end', 'pre_test_start']].dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98201c52-20d4-4984-ace2-474e93a96ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#average comfort, not by gruop\n",
    "\n",
    "# Dictionary to replace comfort level strings with numeric values\n",
    "comfort_map = {\n",
    "    'Very uncomfortable': 1,\n",
    "    'Uncomfortable': 2,\n",
    "    'Neither comfortable nor uncomfortable': 3,\n",
    "    'Comfortable': 4,\n",
    "    'Very comfortable': 5\n",
    "}\n",
    "\n",
    "# List of columns to convert\n",
    "columns_to_convert = ['non_chris', 'comfort_scenario_Sam', 'comfort_scenario_Dan', \n",
    "                      'comfort_scenario_Rebecca', 'non_jes_disc', 'non_beth', 'unclear_scenario_G']\n",
    "\n",
    "# Replace comfort levels with numeric values across the specified columns\n",
    "for column in columns_to_convert:\n",
    "    data[column] = data[column].replace(comfort_map).astype(float)\n",
    "\n",
    "# Calculate average comfort levels for aggregate, consensual, and non-consensual scenarios\n",
    "data['agg_mean'] = data[['non_chris', 'comfort_scenario_Sam', 'comfort_scenario_Dan', \n",
    "                         'comfort_scenario_Rebecca', 'non_jes_disc', 'non_beth', \n",
    "                         'unclear_scenario_G']].mean(axis=1, skipna=True)\n",
    "\n",
    "data['con_mean'] = data[['comfort_scenario_Sam', 'comfort_scenario_Dan', 'comfort_scenario_Rebecca']].mean(axis=1, skipna=True)\n",
    "\n",
    "data['non_mean'] = data[['non_chris', 'non_jes_disc', 'non_beth']].mean(axis=1, skipna=True)\n",
    "\n",
    "# Calculate median comfort levels\n",
    "data['agg_med'] = data[['non_chris', 'comfort_scenario_Sam', 'comfort_scenario_Dan', \n",
    "                        'comfort_scenario_Rebecca', 'non_jes_disc', 'non_beth', \n",
    "                        'unclear_scenario_G']].median(axis=1, skipna=True)\n",
    "\n",
    "data['con_med'] = data[['comfort_scenario_Sam', 'comfort_scenario_Dan', 'comfort_scenario_Rebecca']].median(axis=1, skipna=True)\n",
    "\n",
    "data['non_med'] = data[['non_chris', 'non_jes_disc', 'non_beth']].median(axis=1, skipna=True)\n",
    "\n",
    "# Prepare data for plotting the boxplot of average comfort levels\n",
    "avg_columns = ['agg_mean', 'con_mean', 'non_mean']\n",
    "avg_df = data[avg_columns]\n",
    "\n",
    "# Melt the data for easier plotting\n",
    "data_long = avg_df.melt(var_name='variable', value_name='value')\n",
    "\n",
    "# Map variable names to more readable labels\n",
    "data_long['variable'] = data_long['variable'].map({\n",
    "    'agg_mean': 'Aggregate',\n",
    "    'con_mean': 'Consensual',\n",
    "    'non_mean': 'Non-Consensual'\n",
    "})\n",
    "\n",
    "# Create the boxplot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='variable', y='value', data=data_long)\n",
    "plt.title(\"Average Level of Comfort by Scenario Type\", fontsize=12, fontweight='bold')\n",
    "plt.xlabel(\"Scenario Type\", fontsize=10)\n",
    "plt.ylabel(\"Average Level of Comfort\", fontsize=10)\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.grid(False)  # Remove grid lines\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(\"average_comfort_boxplot.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35bba8f6-205d-462d-9924-1d4bfdea42d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7732f5b7-c151-4be7-a5f7-e5d4508ed615",
   "metadata": {},
   "source": [
    "## Examine Survey-Taking Characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7201bf4c-b7fe-4ec5-8826-11af718926d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Convert 'Duration_in_seconds' to numeric\n",
    "data['duration_seconds'] = pd.to_numeric(data['duration_seconds'], errors='coerce')\n",
    "\n",
    "# Filter the data for participants who finished the survey\n",
    "data_complete = data[data['survey_completed'] == True]\n",
    "\n",
    "# Remove outliers based on the 'duration_seconds' column (mean + 3 * std)\n",
    "mean_val = data_complete['duration_seconds'].mean()\n",
    "sd_val = data_complete['duration_seconds'].std()\n",
    "outlier_threshold = mean_val + 3 * sd_val\n",
    "\n",
    "# Filter data to exclude outliers\n",
    "data_no_outliers = data[data['duration_seconds'] <= outlier_threshold]\n",
    "\n",
    "# Summary statistics for 'duration_seconds' after removing outliers\n",
    "summary_no_outliers = data_no_outliers['duration_seconds'].describe()\n",
    "summary_no_outliers.to_csv('summary_duration_seconds_no_outliers.csv')\n",
    "\n",
    "# Analyze time spent by gender (female participants)\n",
    "data_female_complete = data_complete[data_complete['gender_identity'] == 'Cisgender female']\n",
    "\n",
    "mean_val_female = data_female_complete['duration_seconds'].mean()\n",
    "sd_val_female = data_female_complete['duration_seconds'].std()\n",
    "outlier_threshold_female = mean_val_female + 3 * sd_val_female\n",
    "\n",
    "# Filter data for females to exclude outliers\n",
    "data_female_no_outliers = data_female_complete[data_female_complete['duration_seconds'] <= outlier_threshold_female]\n",
    "\n",
    "# Summary statistics for 'duration_seconds' for females after removing outliers\n",
    "summary_female_no_outliers = data_female_no_outliers['duration_seconds'].describe()\n",
    "summary_female_no_outliers.to_csv('summary_duration_seconds_female_no_outliers.csv')\n",
    "\n",
    "# Convert 'Progress' to numeric\n",
    "data['survey_progress'] = pd.to_numeric(data['survey_progress'], errors='coerce')\n",
    "\n",
    "# Analyze progress for female participants\n",
    "data_female_progress = data[data['gender_identity'] == 'Cisgender female']\n",
    "\n",
    "# Summary of 'survey_progress' for females\n",
    "summary_female_progress = data_female_progress['survey_progress'].describe()\n",
    "summary_female_progress.to_csv('summary_survey_progress_female.csv')\n",
    "\n",
    "print(\"All survey-taking characteristics saved to CSV files.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c02f074-db4d-4aeb-ba3b-d85bb9ebf16d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7fe748-cd3b-4372-89cc-9470fafdaa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert column types for later analysis\n",
    "\n",
    "# List of columns to convert to numeric\n",
    "columns_to_convert = [\n",
    "    'guilt_feelings', 'speak_sex', 'freq_porn', 'religious_affiliation', 'people_comfortable', 'friends_comfortable', \n",
    "    'incident_report', 'freq_masturbation', 'mast_no_activity', 'uncomfy_speak_sex', 'never_speak_activity', \n",
    "    'speak_porn', 'porn_partner', 'dont_know_creation', 'appeals', 'knowledge_creation', 'educ_sex', \n",
    "    'friends_comfortable', 'people_comfortable'\n",
    "]\n",
    "\n",
    "# Loop through the columns and convert them to numeric\n",
    "for column in columns_to_convert:\n",
    "    data[column] = pd.to_numeric(data[column], errors='coerce')\n",
    "\n",
    "# Clean up categorical variables using mapping where necessary\n",
    "# College completed\n",
    "data['education_completed'] = data['education_completed'].map({\n",
    "    'Less than one year': 0, '1 year': 1, '2 years': 2, '3 years': 3, '4 years': 4, '5+ years': 5\n",
    "}).astype(float)\n",
    "\n",
    "# Sexuality to numeric\n",
    "data['sexual_orientation'] = pd.to_numeric(data['sexual_orientation'], errors='coerce')\n",
    "\n",
    "# Age cleanup\n",
    "data['age'] = data['age'].replace({\n",
    "    '24 or older': 24, '23': 23, '22': 22, '21': 21, '20': 20, '19': 19, '18': 18\n",
    "}).astype(float)\n",
    "\n",
    "# Number of partners\n",
    "data['num_partners'] = data['num_partners'].map({\n",
    "    '0': 0, '1-2': 1, '3-4': 2, '5-6': 3, '6 or more': 4\n",
    "}).astype(float)\n",
    "\n",
    "# Assign numeric values for gender\n",
    "data['gender_identity'] = data['gender_identity'].map({\n",
    "    'Cisgender female': 0, 'Cisgender male': 1\n",
    "}).astype(float)\n",
    "\n",
    "# Alcohol consumption per week\n",
    "data['alc_per_week'] = data['alc_per_week'].map({\n",
    "    '0 times per week': 0, '1-2 times per week': 1, '3-4 times per week': 2, '5-6 times per week': 3, '7 or more times per week': 4\n",
    "}).astype(float)\n",
    "\n",
    "# Relationship status\n",
    "data['relationship_status'] = data['relationship_status'].map({\n",
    "    'Yes': 1, 'No': 0, 'Maybe': 0\n",
    "}).astype(float)\n",
    "\n",
    "# Frequency of sex\n",
    "data['freq_sex'] = pd.to_numeric(data['freq_sex'], errors='coerce')\n",
    "\n",
    "# Age first viewed adult material\n",
    "data['age_first_exposure'] = data['age_first_exposure'].map({\n",
    "    '9-11': 1, '12-13': 2, '14-15': 3, '16-17': 4, '18+': 5, 'N/A': 0\n",
    "}).astype(float)\n",
    "\n",
    "# Verify that columns were correctly converted\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5b4937-695d-4c2d-988c-6418c6a577e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666a92da-e1b7-4929-b0c7-41be05f63ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a version of the df that only includes rows where participants included the average prequency that they consume pornography\n",
    "\n",
    "# Filter rows where 'freq_porn' is not NaN\n",
    "data_filtered = data.dropna(subset=['freq_porn'])\n",
    "\n",
    "# Create a binary 'watched_porn' variable based on 'freq_porn'\n",
    "data_filtered['watched_porn'] = np.where(data_filtered['freq_porn'].isin([0, 1]), 0, 1)\n",
    "\n",
    "# Create a binary 'race_white' variable based on race\n",
    "data_filtered['race_white'] = np.where(data_filtered['ethnicity'] == 'White / Caucasian', 1, 0)\n",
    "\n",
    "# Verify the new columns\n",
    "print(data_filtered[['watched_porn', 'race_white']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f0c7cd-3469-4d7f-9e18-c9e5bc7f44c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c856e568-eeef-4d07-9105-29fde9995455",
   "metadata": {},
   "source": [
    "## Comparison with Prior Study\n",
    "This study was partially inspired by a 2017 paper by Cooper and Klein, where they investigate the effect of social variables on pornography consumption. Here, I verify that the results of this survey align with their main findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097eb062-70fd-49da-885e-e3e2a1b742b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the independent variables and dependent variable for the logistic regression model\n",
    "X = data_filtered[['gender_identity', 'age', 'race_white', 'religious_affiliation', 'education_completed', 'sexual_orientation', 'alc_per_week']]\n",
    "X = sm.add_constant(X)  # Add a constant term for the intercept\n",
    "y = data_filtered['watched_porn']\n",
    "\n",
    "# Fit the logistic regression model (equivalent to glm with binomial family in R)\n",
    "modelA = sm.Logit(y, X).fit()\n",
    "\n",
    "# Save the model summary to a text file\n",
    "with open('logistic_regression_summary.txt', 'w') as f:\n",
    "    f.write(modelA.summary().as_text())\n",
    "\n",
    "# Extract null deviance, degrees of freedom, and number of observations\n",
    "null_deviance = modelA.llnull\n",
    "df_null = modelA.df_model + 1  # Adding 1 for intercept\n",
    "n_obs = len(modelA.fittedvalues)\n",
    "\n",
    "# Save null deviance, degrees of freedom, and number of observations into a CSV\n",
    "summary_stats = pd.DataFrame({\n",
    "    'Statistic': ['Null Deviance', 'Degrees of Freedom (Null)', 'Number of Observations'],\n",
    "    'Value': [null_deviance, df_null, n_obs]\n",
    "})\n",
    "\n",
    "summary_stats.to_csv('logistic_regression_summary_stats.csv', index=False)\n",
    "\n",
    "print(\"Logistic regression summary saved to 'logistic_regression_summary.txt' and statistics saved to 'logistic_regression_summary_stats.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529480e4-e18e-4b79-8466-02fa3f9779e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the independent variables and dependent variable for the logistic regression model\n",
    "X = data_filtered[['gender_identity', 'age', 'race_white', 'religious_affiliation', 'education_completed', 'sexual_orientation', 'alc_per_week']]\n",
    "X = sm.add_constant(X)  # Add a constant term for the intercept\n",
    "y = data_filtered['watched_porn']\n",
    "\n",
    "# Fit the logistic regression model\n",
    "modelA = sm.Logit(y, X).fit()\n",
    "\n",
    "# Extract coefficients and standard errors\n",
    "coefficients = modelA.params\n",
    "std_errors = modelA.bse\n",
    "\n",
    "# Calculate odds ratios using exp()\n",
    "odds_ratios = np.exp(coefficients)\n",
    "\n",
    "# Calculate standard errors of the odds ratios\n",
    "odds_ratios_std_errors = odds_ratios * std_errors\n",
    "\n",
    "# Extract p-values from the model\n",
    "p_values = modelA.pvalues\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "result = pd.DataFrame({\n",
    "    'Coefficient': coefficients,\n",
    "    'Std_Error': std_errors,\n",
    "    'Odds_Ratio': odds_ratios,\n",
    "    'Odds_Ratio_Std_Error': odds_ratios_std_errors,\n",
    "    'P_Value': p_values\n",
    "})\n",
    "\n",
    "# Calculate residuals and fitted values\n",
    "residuals = modelA.resid_response\n",
    "fitted_values = modelA.fittedvalues\n",
    "\n",
    "# Calculate chi-squared statistic\n",
    "chi_squared = np.sum((residuals ** 2) / (fitted_values * (1 - fitted_values)))\n",
    "df = len(coefficients) - 1\n",
    "nobs = len(residuals)\n",
    "\n",
    "# Add chi-squared, degrees of freedom, and number of observations to a separate DataFrame\n",
    "chi_squared_df = pd.DataFrame({\n",
    "    'Chi_Squared': [chi_squared],\n",
    "    'Degrees_Freedom': [df],\n",
    "    'N_Obs': [nobs]\n",
    "})\n",
    "\n",
    "# Save the results DataFrame to a CSV\n",
    "result.to_csv('logistic_regression_modelA_results.csv', index=False)\n",
    "\n",
    "# Save chi-squared information to a separate CSV\n",
    "chi_squared_df.to_csv('logistic_regression_modelA_chi_squared.csv', index=False)\n",
    "\n",
    "print(\"Logistic regression results saved to 'logistic_regression_modelA_results.csv' and chi-squared information saved to 'logistic_regression_modelA_chi_squared.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaa29b7-9805-416c-996c-8df56e068a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the independent variables and dependent variable for the logistic regression model (Model B)\n",
    "X_B = data_filtered[['gender_identity', 'age', 'race_white', 'religious_affiliation', 'education_completed', \n",
    "                     'sexual_orientation', 'alc_per_week', 'num_partners', 'relationship_status', 'freq_sex', \n",
    "                     'age_first_exposure', 'freq_masturbation']]\n",
    "X_B = sm.add_constant(X_B)  # Add a constant term for the intercept\n",
    "y_B = data_filtered['watched_porn']\n",
    "\n",
    "# Fit the logistic regression model (Model B)\n",
    "modelB = sm.Logit(y_B, X_B).fit()\n",
    "\n",
    "# Save the model summary to a text file\n",
    "with open('logistic_regression_modelB_summary.txt', 'w') as f:\n",
    "    f.write(modelB.summary().as_text())\n",
    "\n",
    "# Extract null deviance and degrees of freedom\n",
    "null_deviance_B = modelB.llnull\n",
    "df_null_B = modelB.df_model + 1  # Adding 1 for intercept\n",
    "\n",
    "# Number of observations\n",
    "n_obs_B = len(modelB.fittedvalues)\n",
    "\n",
    "# Save null deviance, degrees of freedom, and number of observations to a CSV\n",
    "summary_stats_B = pd.DataFrame({\n",
    "    'Statistic': ['Null Deviance', 'Degrees of Freedom (Null)', 'Number of Observations'],\n",
    "    'Value': [null_deviance_B, df_null_B, n_obs_B]\n",
    "})\n",
    "\n",
    "summary_stats_B.to_csv('logistic_regression_modelB_summary_stats.csv', index=False)\n",
    "\n",
    "# Extract coefficients, standard errors, and p-values\n",
    "coefficients_B = modelB.params\n",
    "std_errors_B = modelB.bse\n",
    "p_values_B = modelB.pvalues\n",
    "\n",
    "# Calculate odds ratios using exp()\n",
    "odds_ratios_B = np.exp(coefficients_B)\n",
    "\n",
    "# Calculate standard errors of the odds ratios\n",
    "odds_ratios_std_errors_B = odds_ratios_B * std_errors_B\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "result_B = pd.DataFrame({\n",
    "    'Coefficient': coefficients_B,\n",
    "    'Std_Error': std_errors_B,\n",
    "    'Odds_Ratio': odds_ratios_B,\n",
    "    'Odds_Ratio_Std_Error': odds_ratios_std_errors_B,\n",
    "    'P_Value': p_values_B\n",
    "})\n",
    "\n",
    "# Calculate residuals and fitted values\n",
    "residuals_B = modelB.resid_response\n",
    "fitted_values_B = modelB.fittedvalues\n",
    "\n",
    "# Calculate chi-squared statistic\n",
    "chi_squared_B = np.sum((residuals_B ** 2) / (fitted_values_B * (1 - fitted_values_B)))\n",
    "df_B = len(coefficients_B) - 1\n",
    "nobs_B = len(residuals_B)\n",
    "\n",
    "# Add chi-squared, degrees of freedom, and number of observations to the results\n",
    "result_B['Chi_Squared'] = chi_squared_B\n",
    "result_B['Degrees_Freedom'] = df_B\n",
    "result_B['N_Obs'] = nobs_B\n",
    "\n",
    "# Save the result DataFrame to a CSV\n",
    "result_B.to_csv('logistic_regression_modelB_results.csv', index=False)\n",
    "\n",
    "print(\"Logistic regression results saved to 'logistic_regression_modelB_results.csv' and summary statistics saved to 'logistic_regression_modelB_summary_stats.csv'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb7ef35-2d2f-4a9c-9f07-23f058864520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Prepare the independent variables and dependent variable for the logistic regression model (Model C)\n",
    "X_C = data_filtered[['gender_identity', 'age', 'race_white', 'religious_affiliation', 'education_completed', \n",
    "                     'sexual_orientation', 'alc_per_week', 'num_partners', 'relationship_status', 'freq_sex', \n",
    "                     'age_first_exposure', 'freq_masturbation', 'speak_porn', 'speak_sex', \n",
    "                     'friends_comfortable', 'people_comfortable']]\n",
    "X_C = sm.add_constant(X_C)  # Add a constant term for the intercept\n",
    "y_C = data_filtered['watched_porn']\n",
    "\n",
    "# Fit the logistic regression model (Model C)\n",
    "modelC = sm.Logit(y_C, X_C).fit()\n",
    "\n",
    "# Save the model summary to a text file\n",
    "with open('logistic_regression_modelC_summary.txt', 'w') as f:\n",
    "    f.write(modelC.summary().as_text())\n",
    "\n",
    "# Extract null deviance and degrees of freedom\n",
    "null_deviance_C = modelC.llnull\n",
    "df_null_C = modelC.df_model + 1  # Adding 1 for intercept\n",
    "\n",
    "# Number of observations\n",
    "n_obs_C = len(modelC.fittedvalues)\n",
    "\n",
    "# Save null deviance, degrees of freedom, and number of observations to a CSV\n",
    "summary_stats_C = pd.DataFrame({\n",
    "    'Statistic': ['Null Deviance', 'Degrees of Freedom (Null)', 'Number of Observations'],\n",
    "    'Value': [null_deviance_C, df_null_C, n_obs_C]\n",
    "})\n",
    "\n",
    "summary_stats_C.to_csv('logistic_regression_modelC_summary_stats.csv', index=False)\n",
    "\n",
    "# Extract coefficients, standard errors, and p-values\n",
    "coefficients_C = modelC.params\n",
    "std_errors_C = modelC.bse\n",
    "p_values_C = modelC.pvalues\n",
    "\n",
    "# Calculate odds ratios using exp()\n",
    "odds_ratios_C = np.exp(coefficients_C)\n",
    "\n",
    "# Calculate standard errors of the odds ratios\n",
    "odds_ratios_std_errors_C = odds_ratios_C * std_errors_C\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "result_C = pd.DataFrame({\n",
    "    'Coefficient': coefficients_C,\n",
    "    'Std_Error': std_errors_C,\n",
    "    'Odds_Ratio': odds_ratios_C,\n",
    "    'Odds_Ratio_Std_Error': odds_ratios_std_errors_C,\n",
    "    'P_Value': p_values_C\n",
    "})\n",
    "\n",
    "# Calculate residuals and fitted values\n",
    "residuals_C = modelC.resid_response\n",
    "fitted_values_C = modelC.fittedvalues\n",
    "\n",
    "# Calculate chi-squared statistic\n",
    "chi_squared_C = np.sum((residuals_C ** 2) / (fitted_values_C * (1 - fitted_values_C)))\n",
    "df_C = len(coefficients_C) - 1\n",
    "nobs_C = len(residuals_C)\n",
    "\n",
    "# Add chi-squared, degrees of freedom, and number of observations to the results\n",
    "result_C['Chi_Squared'] = chi_squared_C\n",
    "result_C['Degrees_Freedom'] = df_C\n",
    "result_C['N_Obs'] = nobs_C\n",
    "\n",
    "# Save the result DataFrame to a CSV\n",
    "result_C.to_csv('logistic_regression_modelC_results.csv', index=False)\n",
    "\n",
    "print(\"Logistic regression results saved to 'logistic_regression_modelC_results.csv' and summary statistics saved to 'logistic_regression_modelC_summary_stats.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3248b509-8a84-4ccb-ba1a-2dcb64ab1abe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ce55d43a-7768-4508-846c-435f98cdd773",
   "metadata": {},
   "source": [
    "## Other Sources of Discomfort\n",
    "In the experiment, participants are asked to rate their level of comfort. However, there may be other elements of the survey-taking process that affect comfort levels. It is useful to understand trends around discomfort more broadly in order to validate that trends in discomfort are related to the treatments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21680da2-d5b5-4cc9-8173-04a2518fd681",
   "metadata": {},
   "outputs": [],
   "source": [
    "#did men often stop taking the survey after reading the vignettes? (sign of discomfort)\n",
    "\n",
    "# Get the index of the 'unclear_scenario_G' column\n",
    "unc_max_col = data.columns.get_loc('unclear_scenario_G')\n",
    "\n",
    "# Select columns from 'unclear_scenario_G' to the end\n",
    "selected_cols = ['gender_identity'] + data.columns[unc_max_col + 1:].tolist()\n",
    "\n",
    "# Subset the data frame with the selected columns\n",
    "data_filtered = data[selected_cols]\n",
    "\n",
    "# Split the data into male and female subsets\n",
    "female_df = data_filtered[data_filtered['gender_identity'] == 0]\n",
    "male_df = data_filtered[data_filtered['gender_identity'] == 1]\n",
    "\n",
    "# Calculate the number of missing values in each row for males and females\n",
    "female_na_count = female_df.isna().sum(axis=1)\n",
    "male_na_count = male_df.isna().sum(axis=1)\n",
    "\n",
    "# Calculate and print the mean number of missing values for each gender\n",
    "mean_female_na = female_na_count.mean()\n",
    "mean_male_na = male_na_count.mean()\n",
    "\n",
    "print(f\"Mean number of missing values (Female): {mean_female_na}\")\n",
    "print(f\"Mean number of missing values (Male): {mean_male_na}\")\n",
    "\n",
    "#now same Q, but by group\n",
    "# Subset the dataset to only include males\n",
    "males = data_filtered[data_filtered['gender_identity'] == 1]\n",
    "\n",
    "# Subset the male dataset to only include \"info\" and \"control\" groups\n",
    "male_info_control = males[males['group_number'].isin(['info', 'control'])]\n",
    "\n",
    "# Create a new column called \"num_nas\" that counts the number of NAs in each row\n",
    "male_info_control['num_nas'] = male_info_control.isna().sum(axis=1)\n",
    "\n",
    "# Calculate the mean number of NAs for males in the \"info\" group and \"control\" group\n",
    "mean_nas_info = male_info_control.loc[male_info_control['group_number'] == 'info', 'num_nas'].mean()\n",
    "mean_nas_control = male_info_control.loc[male_info_control['group_number'] == 'control', 'num_nas'].mean()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean number of NAs for males in the 'info' group: {mean_nas_info}\")\n",
    "print(f\"Mean number of NAs for males in the 'control' group: {mean_nas_control}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb9f39b-c44a-4732-a4b0-970c704802d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#look at trends in time spent on conditions - check to see if they actually read it, and separating out effects for those who did read it\n",
    "\n",
    "# Create new columns for the amount of time spent reading the condition\n",
    "data['control_time_spent'] = np.nan  # Create a column but leave it empty for now\n",
    "data['info_time_spent'] = data['info_group_end'] - data['info_group_start']\n",
    "data['pre_time_spent'] = data['pre_test_end'] - data['pre_test_start']\n",
    "\n",
    "# Calculate mean of control_time_spent for group \"control\"\n",
    "mean_control = data.groupby('group_number')['control_time_spent'].mean().loc['control']\n",
    "\n",
    "# Calculate mean of info_time_spent for group \"info\"\n",
    "mean_info = data.groupby('group_number')['info_time_spent'].mean().loc['info']\n",
    "\n",
    "# Calculate mean of pre_time_spent for group \"pressure\"\n",
    "mean_pressure = data.groupby('group_number')['pre_time_spent'].mean().loc['pressure']\n",
    "\n",
    "# Filter data to include only female participants\n",
    "data_female = data[data['gender_identity'] == 0]\n",
    "\n",
    "# Convert 'info_feels_pos' and 'pre_feels_pos' to numeric\n",
    "data['info_feels_pos'] = pd.to_numeric(data['info_feels_pos'], errors='coerce')\n",
    "data['pre_feels_pos'] = pd.to_numeric(data['pre_feels_pos'], errors='coerce')\n",
    "\n",
    "# Summary statistics for 'info_feels_pos'\n",
    "print(\"Summary of 'info_feels_pos':\\n\", data['info_feels_pos'].describe())\n",
    "\n",
    "# Remove rows where less than a certain amount of time was spent on specific conditions\n",
    "data_filtered = data[~((data['group_number'] == 'pressure') & (data['pre_time_spent'] < 30))]\n",
    "data_filtered = data_filtered[~((data['group_number'] == 'info') & (data['info_time_spent'] < 20))]\n",
    "\n",
    "# Verify the filtering\n",
    "print(f\"Rows remaining after filtering: {len(data_filtered)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c21581-2c2d-4616-b6de-450c20b9aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r did men stop taking the survey after porn vignettes (BY group)\n",
    "\n",
    "# Get the index of the 'unclear_scenario_G' column\n",
    "unc_max_col = data.columns.get_loc('unclear_scenario_G')\n",
    "\n",
    "# Select columns from 'unclear_scenario_G' to the end, including 'gender_identity'\n",
    "selected_cols = ['gender_identity'] + data.columns[unc_max_col + 1:].tolist()\n",
    "\n",
    "# Subset the data with the selected columns\n",
    "data_filtered = data[selected_cols]\n",
    "\n",
    "# Subset the dataset to only include males (gender == 0)\n",
    "males = data_filtered[data_filtered['gender_identity'] == 0]\n",
    "\n",
    "# Subset the male dataset to only include \"info\" and \"control\" groups\n",
    "male_info_control = males[males['group_number'].isin(['info', 'control'])]\n",
    "\n",
    "# Create a new column called \"num_nas\" that counts the number of NAs in each row\n",
    "male_info_control['num_nas'] = male_info_control.isna().sum(axis=1)\n",
    "\n",
    "# Calculate the mean number of NAs for males in the \"info\" group and \"control\" group\n",
    "mean_nas_info = male_info_control.loc[male_info_control['group_number'] == 'info', 'num_nas'].mean()\n",
    "mean_nas_control = male_info_control.loc[male_info_control['group_number'] == 'control', 'num_nas'].mean()\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean number of NAs for males in the 'info' group: {mean_nas_info}\")\n",
    "print(f\"Mean number of NAs for males in the 'control' group: {mean_nas_control}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2810fcf3-8f30-47a5-9a99-c8c263f77eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27415f72-c92b-4445-b474-f37c2fdf3244",
   "metadata": {},
   "source": [
    "## Final Versions of Figures for the Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4cf967-5aec-4e86-9bf6-e1bddb1d8832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the theme for plots\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Create new treatment variable and map conditions\n",
    "data['treatment'] = data['group_number'].replace({'info': 'treatment', 'pressure': 'treatment', 'control': 'control'})\n",
    "\n",
    "# Melt the data for easy plotting\n",
    "avgs = ['treatment', 'agg_mean', 'con_mean', 'non_mean', 'unclear_scenario_G']\n",
    "avg_df = data[avgs]\n",
    "data_long = avg_df.melt(id_vars='treatment', var_name='variable', value_name='value')\n",
    "\n",
    "# Update variable names for better readability\n",
    "data_long['variable'] = data_long['variable'].replace({\n",
    "    'agg_mean': 'Aggregate', \n",
    "    'con_mean': 'Consensual', \n",
    "    'non_mean': 'Non-Consensual', \n",
    "    'unclear_scenario_G': 'Unclear'\n",
    "})\n",
    "\n",
    "# Drop rows with missing values\n",
    "data_long = data_long.dropna(subset=['value'])\n",
    "\n",
    "# Summary statistics and standard errors for plotting\n",
    "data_long_summary = data_long.groupby(['treatment', 'variable']).agg(\n",
    "    mean_value=('value', 'mean'),\n",
    "    se=('value', lambda x: np.std(x, ddof=1) / np.sqrt(len(x)))\n",
    ").reset_index()\n",
    "\n",
    "# Save summary statistics to CSV\n",
    "data_long_summary.to_csv('summary_statistics_all_participants.csv', index=False)\n",
    "\n",
    "# Plotting: Boxplot for average comfort by scenario type, split by treatment\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='variable', y='value', hue='treatment', data=data_long, palette='muted')\n",
    "plt.title('Level of Comfort with Scenarios for all Participants')\n",
    "plt.xlabel('Scenario Type')\n",
    "plt.ylabel('Average Level of Comfort')\n",
    "plt.savefig('comfort_scenarios_boxplot_all_participants.png')\n",
    "plt.close()\n",
    "\n",
    "# Bar plot with error bars for mean values\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='variable', y='mean_value', hue='treatment', data=data_long_summary, \n",
    "            palette={'info': '#9DC3E6', 'pressure': '#FAC8CD', 'control': '#CCF0E6'}, dodge=True, ci=None)\n",
    "\n",
    "# Add error bars\n",
    "for idx, row in data_long_summary.iterrows():\n",
    "    plt.errorbar(x=idx % len(data_long_summary['variable'].unique()), y=row['mean_value'], \n",
    "                 yerr=row['se'], fmt='none', color='black', capsize=5)\n",
    "\n",
    "plt.title('Average Level of Comfort by Treatment and Scenario Type')\n",
    "plt.xlabel('Scenario Type')\n",
    "plt.ylabel('Average Level of Comfort')\n",
    "plt.savefig('comfort_by_treatment_and_scenario_barplot.png')\n",
    "plt.close()\n",
    "\n",
    "# Create plots for male and female participants separately\n",
    "for gender, gender_name in [(0, 'Female'), (1, 'Male')]:\n",
    "    gender_data = data[data['gender_identity'] == gender]\n",
    "    avg_df_gender = gender_data[['treatment', 'agg_mean', 'con_mean', 'non_mean', 'unclear_scenario_G']]\n",
    "    data_long_gender = avg_df_gender.melt(id_vars='treatment', var_name='variable', value_name='value')\n",
    "    data_long_gender['variable'] = data_long_gender['variable'].replace({\n",
    "        'agg_mean': 'Aggregate', \n",
    "        'con_mean': 'Consensual', \n",
    "        'non_mean': 'Non-Consensual', \n",
    "        'unclear_scenario_G': 'Unclear'\n",
    "    })\n",
    "    data_long_gender_summary = data_long_gender.groupby(['treatment', 'variable']).agg(\n",
    "        mean_value=('value', 'mean'),\n",
    "        se=('value', lambda x: np.std(x, ddof=1) / np.sqrt(len(x)))\n",
    "    ).reset_index()\n",
    "\n",
    "    # Save summary statistics to CSV for each gender\n",
    "    data_long_gender_summary.to_csv(f'summary_statistics_{gender_name.lower()}.csv', index=False)\n",
    "\n",
    "    # Bar plot for each gender\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='variable', y='mean_value', hue='treatment', data=data_long_gender_summary, dodge=True, \n",
    "                palette={'info': '#9DC3E6', 'pressure': '#FAC8CD', 'control': '#CCF0E6'})\n",
    "    \n",
    "    # Add error bars\n",
    "    for idx, row in data_long_gender_summary.iterrows():\n",
    "        plt.errorbar(x=idx % len(data_long_gender_summary['variable'].unique()), y=row['mean_value'], \n",
    "                     yerr=row['se'], fmt='none', color='black', capsize=5)\n",
    "    \n",
    "    plt.title(f'Average Level of Comfort by Scenario Type - {gender_name}')\n",
    "    plt.xlabel('Scenario Type')\n",
    "    plt.ylabel('Average Level of Comfort')\n",
    "    plt.savefig(f'comfort_by_scenario_{gender_name.lower()}.png')\n",
    "    plt.close()\n",
    "\n",
    "# Overall plot for male and female participants for all groups\n",
    "data_long_summary['treatment'] = data_long_summary['treatment'].replace({0: 'female', 1: 'male'})\n",
    "data_long_summary = data_long_summary.dropna(subset=['treatment'])\n",
    "\n",
    "# Plot for male and female participants\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='variable', y='mean_value', hue='treatment', data=data_long_summary, dodge=True, \n",
    "            palette={'female': '#FAC8CD', 'male': '#9DC3E6'})\n",
    "plt.title('Average Level of Comfort by Gender')\n",
    "plt.xlabel('Scenario Type')\n",
    "plt.ylabel('Average Level of Comfort')\n",
    "plt.savefig('comfort_by_gender_barplot.png')\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eef9fcd-f0b5-495f-995b-50fb890fa723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to prepare data for plotting\n",
    "def prepare_data(data, group_filter):\n",
    "    # Subset the data by group (control, info, pressure)\n",
    "    data_group = data[data['group_number'] == group_filter].copy()\n",
    "\n",
    "    # Map gender to treatment\n",
    "    data_group['treatment'] = data_group['gender_identity'].replace({0: 'female', 1: 'male'})\n",
    "\n",
    "    # Melt the data for easy plotting\n",
    "    avgs = ['treatment', 'con_mean', 'non_mean', 'unclear_scenario_G']\n",
    "    avg_df = data_group[avgs]\n",
    "    data_long = avg_df.melt(id_vars='treatment', var_name='variable', value_name='value')\n",
    "\n",
    "    # Rename the variable for clarity\n",
    "    data_long['variable'] = data_long['variable'].replace({\n",
    "        'con_mean': 'Consensual',\n",
    "        'non_mean': 'Non-Consensual',\n",
    "        'unclear_scenario_G': 'Unclear'\n",
    "    })\n",
    "\n",
    "    # Group by treatment and variable, calculate mean and standard error\n",
    "    data_long_summary = data_long.groupby(['treatment', 'variable']).agg(\n",
    "        mean_value=('value', 'mean'),\n",
    "        se=('value', lambda x: np.std(x, ddof=1) / np.sqrt(len(x)))\n",
    "    ).reset_index()\n",
    "\n",
    "    # Save summary statistics to CSV for each group\n",
    "    data_long_summary.to_csv(f'summary_statistics_{group_filter}.csv', index=False)\n",
    "\n",
    "    return data_long_summary\n",
    "\n",
    "# Prepare data for the \"control\", \"info\", and \"pressure\" groups\n",
    "data_control = prepare_data(data, 'control')\n",
    "data_info = prepare_data(data, 'info')\n",
    "data_pressure = prepare_data(data, 'pressure')\n",
    "\n",
    "# Function to create bar plots with error bars\n",
    "def plot_bar(data, title, ax):\n",
    "    sns.barplot(x='variable', y='mean_value', hue='treatment', data=data, dodge=True, palette={'female': '#FAC8CD', 'male': '#9DC3E6'}, ax=ax)\n",
    "    \n",
    "    # Add error bars\n",
    "    for idx, row in data.iterrows():\n",
    "        ax.errorbar(x=idx % len(data['variable'].unique()), y=row['mean_value'], \n",
    "                     yerr=row['se'], fmt='none', color='black', capsize=5)\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('Scenario Type')\n",
    "    ax.set_ylabel('Mean Comfort')\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Set up the grid for plotting the three groups together\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Plot for \"control\" group\n",
    "plot_bar(data_control, 'a. Control', axes[0])\n",
    "\n",
    "# Plot for \"info\" group\n",
    "plot_bar(data_info, 'b. Information', axes[1])\n",
    "\n",
    "# Plot for \"pressure\" group\n",
    "plot_bar(data_pressure, 'c. Social Pressure', axes[2])\n",
    "\n",
    "# Adjust layout for better spacing\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "plt.savefig('comfort_by_scenario_type.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"Summary statistics saved as CSV files and plots saved as 'comfort_by_scenario_type.png'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33f8a2e-1eaf-4fdc-a74f-94ae1c9d7a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb85c71f-0d16-45aa-9cb2-17211277ede1",
   "metadata": {},
   "source": [
    "## Regression Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff1e256-0b6f-4ec0-b5a6-b533d85f7a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Recode gender and combine cis and trans\n",
    "data['gender_identity'] = data['gender_identity'].replace({0: 'female', 1: 'male'})\n",
    "\n",
    "# 2. Linear regression models with interaction terms\n",
    "# Define a function to run and save regression models\n",
    "def run_regression(formula, data, model_name):\n",
    "    model = ols(formula, data=data).fit()\n",
    "    # Save the summary to a text file\n",
    "    with open(f'{model_name}_summary.txt', 'w') as f:\n",
    "        f.write(model.summary().as_text())\n",
    "    return model\n",
    "\n",
    "# Model 1: Aggregate mean regression\n",
    "agg_model = run_regression('agg_mean ~ treatment + guilt_feelings + treatment*guilt_feelings + people_comfortable + friends_comfortable + freq_porn + speak_sex + religious_affiliation + gender_identity + treatment*gender_identity', data, 'agg_mean_regression')\n",
    "\n",
    "# Model 2: Consensual mean regression\n",
    "con_model = run_regression('con_mean ~ treatment + guilt_feelings + treatment*guilt_feelings + people_comfortable + friends_comfortable + freq_porn + speak_sex + religious_affiliation + gender_identity + treatment*gender_identity', data, 'con_mean_regression')\n",
    "\n",
    "# Model 3: Non-consensual mean regression\n",
    "non_model = run_regression('non_mean ~ treatment + guilt_feelings + treatment*guilt_feelings + people_comfortable + friends_comfortable + freq_porn + speak_sex + religious_affiliation + gender_identity + treatment*gender_identity', data, 'non_mean_regression')\n",
    "\n",
    "# Model 4: Unclear mean regression\n",
    "unclear_model = run_regression('unclear_scenario_G ~ treatment + guilt_feelings + treatment*guilt_feelings + people_comfortable + friends_comfortable + freq_porn + speak_sex + religious_affiliation + gender_identity + treatment*gender_identity', data, 'unclear_mean_regression')\n",
    "\n",
    "# 3. Run regression models for low comfort participants\n",
    "data_low = data[data['agg_mean'] <= 3]\n",
    "agg_low_model = run_regression('agg_mean ~ treatment + guilt_feelings + treatment*guilt_feelings + people_comfortable + friends_comfortable + freq_porn + speak_sex + religious_affiliation + gender_identity + treatment*gender_identity', data_low, 'agg_low_mean_regression')\n",
    "\n",
    "# Run regression models for high comfort participants\n",
    "data_high = data[data['agg_mean'] >= 3]\n",
    "agg_high_model = run_regression('agg_mean ~ treatment + guilt_feelings + treatment*guilt_feelings + people_comfortable + friends_comfortable + freq_porn + speak_sex + religious_affiliation + gender_identity + treatment*gender_identity', data_high, 'agg_high_mean_regression')\n",
    "\n",
    "# 4. Mean comparisons between men and women\n",
    "# Subset the data based on group_number\n",
    "data_control = data[data['group_number'] == \"control\"]\n",
    "data_info = data[data['group_number'] == \"info\"]\n",
    "data_pressure = data[data['group_number'] == \"pressure\"]\n",
    "\n",
    "# Calculate mean for agg_mean across groups (control, info, pressure)\n",
    "mean_control = data_control['agg_mean'].mean()\n",
    "mean_info = data_info['agg_mean'].mean()\n",
    "mean_pressure = data_pressure['agg_mean'].mean()\n",
    "\n",
    "# Save the means to a CSV file\n",
    "means_df = pd.DataFrame({\n",
    "    'Group': ['Control', 'Info', 'Pressure'],\n",
    "    'Mean': [mean_control, mean_info, mean_pressure]\n",
    "})\n",
    "means_df.to_csv('mean_comparisons.csv', index=False)\n",
    "\n",
    "# Calculate sample mean, standard error, z-score, and p-value for 'info' group\n",
    "se_info = data_info['agg_mean'].std() / np.sqrt(len(data_info))\n",
    "z_score_info = (mean_info - mean_control) / se_info\n",
    "p_value_info = 2 * (1 - stats.norm.cdf(abs(z_score_info)))\n",
    "\n",
    "# Calculate sample mean, standard error, z-score, and p-value for 'pressure' group\n",
    "se_pressure = data_pressure['agg_mean'].std() / np.sqrt(len(data_pressure))\n",
    "z_score_pressure = (mean_pressure - mean_control) / se_pressure\n",
    "p_value_pressure = 2 * (1 - stats.norm.cdf(abs(z_score_pressure)))\n",
    "\n",
    "# Save the z-scores and p-values to a CSV file\n",
    "z_scores_df = pd.DataFrame({\n",
    "    'Comparison': ['Info vs Control', 'Pressure vs Control'],\n",
    "    'Z-Score': [z_score_info, z_score_pressure],\n",
    "    'P-Value': [p_value_info, p_value_pressure]\n",
    "})\n",
    "z_scores_df.to_csv('z_scores_p_values.csv', index=False)\n",
    "\n",
    "print(\"Regression summaries saved as text files and statistical results saved as CSV files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8483866d-707f-4373-8889-b65198a76d98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b7fae72d-bbe6-46b4-b9ef-331de08ad879",
   "metadata": {},
   "source": [
    "## Significance of treatments by sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04a1712-fe4a-408a-bf3b-7df915ddbfb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for men\n",
    "\n",
    "# Subset the data for males by group number (control, info, pressure)\n",
    "data_male_control = data_male[data_male['group_number'] == 'control']\n",
    "data_male_info = data_male[data_male['group_number'] == 'info']\n",
    "data_male_pressure = data_male[data_male['group_number'] == 'pressure']\n",
    "\n",
    "# Filter out rows with missing values for agg_mean\n",
    "data_male_control_agg = data_male_control.dropna(subset=['agg_mean'])\n",
    "data_male_info_agg = data_male_info.dropna(subset=['agg_mean'])\n",
    "data_male_pressure_agg = data_male_pressure.dropna(subset=['agg_mean'])\n",
    "\n",
    "# Calculate means for agg_mean\n",
    "mean_control_agg = data_male_control_agg['agg_mean'].mean()\n",
    "mean_info_agg = data_male_info_agg['agg_mean'].mean()\n",
    "mean_pressure_agg = data_male_pressure_agg['agg_mean'].mean()\n",
    "\n",
    "# Z-test: Compare agg_mean between info and control groups\n",
    "sample_mean_info = data_male_info_agg['agg_mean'].mean()\n",
    "se_info = data_male_info_agg['agg_mean'].std() / np.sqrt(len(data_male_info_agg))\n",
    "z_score_info = (sample_mean_info - mean_control_agg) / se_info\n",
    "p_value_info = 2 * (1 - stats.norm.cdf(abs(z_score_info)))\n",
    "\n",
    "# Z-test: Compare agg_mean between pressure and control groups\n",
    "sample_mean_pressure = data_male_pressure_agg['agg_mean'].mean()\n",
    "se_pressure = data_male_pressure_agg['agg_mean'].std() / np.sqrt(len(data_male_pressure_agg))\n",
    "z_score_pressure = (sample_mean_pressure - mean_control_agg) / se_pressure\n",
    "p_value_pressure = 2 * (1 - stats.norm.cdf(abs(z_score_pressure)))\n",
    "\n",
    "# Save agg_mean results to a CSV\n",
    "agg_mean_results = pd.DataFrame({\n",
    "    'Group': ['Control', 'Info', 'Pressure'],\n",
    "    'Mean': [mean_control_agg, mean_info_agg, mean_pressure_agg],\n",
    "    'Z-Score': [np.nan, z_score_info, z_score_pressure],\n",
    "    'P-Value': [np.nan, p_value_info, p_value_pressure]\n",
    "})\n",
    "agg_mean_results.to_csv('agg_mean_male_comparisons.csv', index=False)\n",
    "\n",
    "# Subset the data for con_mean\n",
    "data_male_control_con = data_male_control.dropna(subset=['con_mean'])\n",
    "data_male_info_con = data_male_info.dropna(subset=['con_mean'])\n",
    "data_male_pressure_con = data_male_pressure.dropna(subset=['con_mean'])\n",
    "\n",
    "# Calculate means for con_mean\n",
    "mean_control_con = data_male_control_con['con_mean'].mean()\n",
    "mean_info_con = data_male_info_con['con_mean'].mean()\n",
    "mean_pressure_con = data_male_pressure_con['con_mean'].mean()\n",
    "\n",
    "# Z-test: Compare con_mean between info and control groups\n",
    "sample_mean_con_info = data_male_info_con['con_mean'].mean()\n",
    "se_con_info = data_male_info_con['con_mean'].std() / np.sqrt(len(data_male_info_con))\n",
    "z_score_con_info = (sample_mean_con_info - mean_control_con) / se_con_info\n",
    "p_value_con_info = 2 * (1 - stats.norm.cdf(abs(z_score_con_info)))\n",
    "\n",
    "# Z-test: Compare con_mean between pressure and control groups\n",
    "sample_mean_con_pressure = data_male_pressure_con['con_mean'].mean()\n",
    "se_con_pressure = data_male_pressure_con['con_mean'].std() / np.sqrt(len(data_male_pressure_con))\n",
    "z_score_con_pressure = (sample_mean_con_pressure - mean_control_con) / se_con_pressure\n",
    "p_value_con_pressure = 2 * (1 - stats.norm.cdf(abs(z_score_con_pressure)))\n",
    "\n",
    "# Save con_mean results to a CSV\n",
    "con_mean_results = pd.DataFrame({\n",
    "    'Group': ['Control', 'Info', 'Pressure'],\n",
    "    'Mean': [mean_control_con, mean_info_con, mean_pressure_con],\n",
    "    'Z-Score': [np.nan, z_score_con_info, z_score_con_pressure],\n",
    "    'P-Value': [np.nan, p_value_con_info, p_value_con_pressure]\n",
    "})\n",
    "con_mean_results.to_csv('con_mean_male_comparisons.csv', index=False)\n",
    "\n",
    "print(\"Results saved to 'agg_mean_male_comparisons.csv' and 'con_mean_male_comparisons.csv'.\")\n",
    "\n",
    "#same stats, for non-concensual only\n",
    "\n",
    "# Subset the data for males by group number (control, info, pressure)\n",
    "data_male_control = data_male[data_male['group_number'] == 'control']\n",
    "data_male_info = data_male[data_male['group_number'] == 'info']\n",
    "data_male_pressure = data_male[data_male['group_number'] == 'pressure']\n",
    "\n",
    "# Filter out rows with missing values for non_mean\n",
    "data_male_control_non_mean = data_male_control.dropna(subset=['non_mean'])\n",
    "data_male_info_non_mean = data_male_info.dropna(subset=['non_mean'])\n",
    "data_male_pressure_non_mean = data_male_pressure.dropna(subset=['non_mean'])\n",
    "\n",
    "# Calculate means for non_mean\n",
    "mean_control_non_mean = data_male_control_non_mean['non_mean'].mean()\n",
    "mean_info_non_mean = data_male_info_non_mean['non_mean'].mean()\n",
    "mean_pressure_non_mean = data_male_pressure_non_mean['non_mean'].mean()\n",
    "\n",
    "# Z-test: Compare non_mean between info and control groups\n",
    "sample_mean_info = data_male_info_non_mean['non_mean'].mean()\n",
    "se_info = data_male_info_non_mean['non_mean'].std() / np.sqrt(len(data_male_info_non_mean))\n",
    "z_score_info = (sample_mean_info - mean_control_non_mean) / se_info\n",
    "p_value_info = 2 * (1 - stats.norm.cdf(abs(z_score_info)))\n",
    "\n",
    "# Z-test: Compare non_mean between pressure and control groups\n",
    "sample_mean_pressure = data_male_pressure_non_mean['non_mean'].mean()\n",
    "se_pressure = data_male_pressure_non_mean['non_mean'].std() / np.sqrt(len(data_male_pressure_non_mean))\n",
    "z_score_pressure = (sample_mean_pressure - mean_control_non_mean) / se_pressure\n",
    "p_value_pressure = 2 * (1 - stats.norm.cdf(abs(z_score_pressure)))\n",
    "\n",
    "# Save non_mean results to a CSV\n",
    "non_mean_results = pd.DataFrame({\n",
    "    'Group': ['Control', 'Info', 'Pressure'],\n",
    "    'Mean': [mean_control_non_mean, mean_info_non_mean, mean_pressure_non_mean],\n",
    "    'Z-Score': [np.nan, z_score_info, z_score_pressure],\n",
    "    'P-Value': [np.nan, p_value_info, p_value_pressure]\n",
    "})\n",
    "non_mean_results.to_csv('non_mean_male_comparisons.csv', index=False)\n",
    "\n",
    "# Z-test for pressure group comparing non_mean to control group's con_mean\n",
    "sample_mean_pressure = data_male_pressure_non_mean['non_mean'].mean()\n",
    "se_pressure = data_male_pressure_non_mean['non_mean'].std() / np.sqrt(len(data_male_pressure_non_mean))\n",
    "\n",
    "# Compare pressure group 'non_mean' to control group's 'con_mean'\n",
    "z_score_con_pressure = (sample_mean_pressure - data_male_control_con_mean['con_mean'].mean()) / se_pressure\n",
    "p_value_con_pressure = 2 * (1 - stats.norm.cdf(abs(z_score_con_pressure)))\n",
    "\n",
    "# Save pressure vs control con_mean comparison to a CSV\n",
    "pressure_vs_control_con_mean = pd.DataFrame({\n",
    "    'Comparison': ['Pressure non_mean vs Control con_mean'],\n",
    "    'Z-Score': [z_score_con_pressure],\n",
    "    'P-Value': [p_value_con_pressure]\n",
    "})\n",
    "pressure_vs_control_con_mean.to_csv('pressure_vs_control_con_mean.csv', index=False)\n",
    "\n",
    "# Repeat for unclear consent scenarios (unc_max)\n",
    "# Filter out rows with missing values for unc_max\n",
    "data_male_control_unc_max = data_male_control.dropna(subset=['unc_max'])\n",
    "data_male_info_unc_max = data_male_info.dropna(subset=['unc_max'])\n",
    "data_male_pressure_unc_max = data_male_pressure.dropna(subset=['unc_max'])\n",
    "\n",
    "# Calculate means for unc_max\n",
    "mean_control_unc_max = data_male_control_unc_max['unc_max'].mean()\n",
    "mean_info_unc_max = data_male_info_unc_max['unc_max'].mean()\n",
    "mean_pressure_unc_max = data_male_pressure_unc_max['unc_max'].mean()\n",
    "\n",
    "# Z-test: Compare unc_max between info and control groups\n",
    "sample_mean_info = data_male_info_unc_max['unc_max'].mean()\n",
    "se_info = data_male_info_unc_max['unc_max'].std() / np.sqrt(len(data_male_info_unc_max))\n",
    "z_score_info = (sample_mean_info - mean_control_unc_max) / se_info\n",
    "p_value_info = 2 * (1 - stats.norm.cdf(abs(z_score_info)))\n",
    "\n",
    "# Z-test: Compare unc_max between pressure and control groups\n",
    "sample_mean_pressure = data_male_pressure_unc_max['unc_max'].mean()\n",
    "se_pressure = data_male_pressure_unc_max['unc_max'].std() / np.sqrt(len(data_male_pressure_unc_max))\n",
    "z_score_pressure = (sample_mean_pressure - mean_control_unc_max) / se_pressure\n",
    "p_value_pressure = 2 * (1 - stats.norm.cdf(abs(z_score_pressure)))\n",
    "\n",
    "# Save unc_max results to a CSV\n",
    "unc_max_results = pd.DataFrame({\n",
    "    'Group': ['Control', 'Info', 'Pressure'],\n",
    "    'Mean': [mean_control_unc_max, mean_info_unc_max, mean_pressure_unc_max],\n",
    "    'Z-Score': [np.nan, z_score_info, z_score_pressure],\n",
    "    'P-Value': [np.nan, p_value_info, p_value_pressure]\n",
    "})\n",
    "unc_max_results.to_csv('unc_max_male_comparisons.csv', index=False)\n",
    "\n",
    "print(\"Results saved to 'non_mean_male_comparisons.csv', 'pressure_vs_control_con_mean.csv', and 'unc_max_male_comparisons.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ba7fe-e229-4ca1-9312-f5303b1c52aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for women\n",
    "\n",
    "# Function to calculate z-scores and p-values\n",
    "def calculate_z_test(info_mean, control_mean, se):\n",
    "    z_score = (info_mean - control_mean) / se\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "    return z_score, p_value\n",
    "\n",
    "### 1. Agg Mean Analysis for Females\n",
    "\n",
    "# Filter out rows with missing values for agg_mean\n",
    "data_female_control_agg = data_female_control.dropna(subset=['agg_mean'])\n",
    "data_female_info_agg = data_female_info.dropna(subset=['agg_mean'])\n",
    "data_female_pressure_agg = data_female_pressure.dropna(subset=['agg_mean'])\n",
    "\n",
    "# Calculate means\n",
    "mean_control_agg = data_female_control_agg['agg_mean'].mean()\n",
    "mean_info_agg = data_female_info_agg['agg_mean'].mean()\n",
    "mean_pressure_agg = data_female_pressure_agg['agg_mean'].mean()\n",
    "\n",
    "# Z-test: Compare agg_mean between info and control groups\n",
    "se_info = data_female_info_agg['agg_mean'].std() / np.sqrt(len(data_female_info_agg))\n",
    "z_score_info, p_value_info = calculate_z_test(mean_info_agg, mean_control_agg, se_info)\n",
    "\n",
    "# Z-test: Compare agg_mean between pressure and control groups\n",
    "se_pressure = data_female_pressure_agg['agg_mean'].std() / np.sqrt(len(data_female_pressure_agg))\n",
    "z_score_pressure, p_value_pressure = calculate_z_test(mean_pressure_agg, mean_control_agg, se_pressure)\n",
    "\n",
    "# Save agg_mean results to a CSV\n",
    "agg_mean_results = pd.DataFrame({\n",
    "    'Group': ['Control', 'Info', 'Pressure'],\n",
    "    'Mean': [mean_control_agg, mean_info_agg, mean_pressure_agg],\n",
    "    'Z-Score': [np.nan, z_score_info, z_score_pressure],\n",
    "    'P-Value': [np.nan, p_value_info, p_value_pressure]\n",
    "})\n",
    "agg_mean_results.to_csv('agg_mean_female_comparisons.csv', index=False)\n",
    "\n",
    "### 2. Con Mean Analysis for Females\n",
    "\n",
    "# Filter out rows with missing values for con_mean\n",
    "data_female_control_con = data_female_control.dropna(subset=['con_mean'])\n",
    "data_female_info_con = data_female_info.dropna(subset=['con_mean'])\n",
    "data_female_pressure_con = data_female_pressure.dropna(subset=['con_mean'])\n",
    "\n",
    "# Calculate means\n",
    "mean_control_con = data_female_control_con['con_mean'].mean()\n",
    "mean_info_con = data_female_info_con['con_mean'].mean()\n",
    "mean_pressure_con = data_female_pressure_con['con_mean'].mean()\n",
    "\n",
    "# Z-test: Compare con_mean between info and control groups\n",
    "se_info_con = data_female_info_con['con_mean'].std() / np.sqrt(len(data_female_info_con))\n",
    "z_score_info_con, p_value_info_con = calculate_z_test(mean_info_con, mean_control_con, se_info_con)\n",
    "\n",
    "# Z-test: Compare con_mean between pressure and control groups\n",
    "se_pressure_con = data_female_pressure_con['con_mean'].std() / np.sqrt(len(data_female_pressure_con))\n",
    "z_score_pressure_con, p_value_pressure_con = calculate_z_test(mean_pressure_con, mean_control_con, se_pressure_con)\n",
    "\n",
    "# Save con_mean results to a CSV\n",
    "con_mean_results = pd.DataFrame({\n",
    "    'Group': ['Control', 'Info', 'Pressure'],\n",
    "    'Mean': [mean_control_con, mean_info_con, mean_pressure_con],\n",
    "    'Z-Score': [np.nan, z_score_info_con, z_score_pressure_con],\n",
    "    'P-Value': [np.nan, p_value_info_con, p_value_pressure_con]\n",
    "})\n",
    "con_mean_results.to_csv('con_mean_female_comparisons.csv', index=False)\n",
    "\n",
    "### 3. Non Mean Analysis for Females\n",
    "\n",
    "# Filter out rows with missing values for non_mean\n",
    "data_female_control_non = data_female_control.dropna(subset=['non_mean'])\n",
    "data_female_info_non = data_female_info.dropna(subset=['non_mean'])\n",
    "data_female_pressure_non = data_female_pressure.dropna(subset=['non_mean'])\n",
    "\n",
    "# Calculate means\n",
    "mean_control_non = data_female_control_non['non_mean'].mean()\n",
    "mean_info_non = data_female_info_non['non_mean'].mean()\n",
    "mean_pressure_non = data_female_pressure_non['non_mean'].mean()\n",
    "\n",
    "# Z-test: Compare non_mean between info and control groups\n",
    "se_info_non = data_female_info_non['non_mean'].std() / np.sqrt(len(data_female_info_non))\n",
    "z_score_info_non, p_value_info_non = calculate_z_test(mean_info_non, mean_control_non, se_info_non)\n",
    "\n",
    "# Z-test: Compare non_mean between pressure and control groups\n",
    "se_pressure_non = data_female_pressure_non['non_mean'].std() / np.sqrt(len(data_female_pressure_non))\n",
    "z_score_pressure_non, p_value_pressure_non = calculate_z_test(mean_pressure_non, mean_control_non, se_pressure_non)\n",
    "\n",
    "# Save non_mean results to a CSV\n",
    "non_mean_results = pd.DataFrame({\n",
    "    'Group': ['Control', 'Info', 'Pressure'],\n",
    "    'Mean': [mean_control_non, mean_info_non, mean_pressure_non],\n",
    "    'Z-Score': [np.nan, z_score_info_non, z_score_pressure_non],\n",
    "    'P-Value': [np.nan, p_value_info_non, p_value_pressure_non]\n",
    "})\n",
    "non_mean_results.to_csv('non_mean_female_comparisons.csv', index=False)\n",
    "\n",
    "### 4. Unclear Mean Analysis for Females\n",
    "\n",
    "# Filter out rows with missing values for unc_max\n",
    "data_female_control_unc_max = data_female_control.dropna(subset=['unc_max'])\n",
    "data_female_info_unc_max = data_female_info.dropna(subset=['unc_max'])\n",
    "data_female_pressure_unc_max = data_female_pressure.dropna(subset=['unc_max'])\n",
    "\n",
    "# Calculate means\n",
    "mean_control_unc_max = data_female_control_unc_max['unc_max'].mean()\n",
    "mean_info_unc_max = data_female_info_unc_max['unc_max'].mean()\n",
    "mean_pressure_unc_max = data_female_pressure_unc_max['unc_max'].mean()\n",
    "\n",
    "# Z-test: Compare unc_max between info and control groups\n",
    "se_info_unc_max = data_female_info_unc_max['unc_max'].std() / np.sqrt(len(data_female_info_unc_max))\n",
    "z_score_info_unc_max, p_value_info_unc_max = calculate_z_test(mean_info_unc_max, mean_control_unc_max, se_info_unc_max)\n",
    "\n",
    "# Z-test: Compare unc_max between pressure and control groups\n",
    "se_pressure_unc_max = data_female_pressure_unc_max['unc_max'].std() / np.sqrt(len(data_female_pressure_unc_max))\n",
    "z_score_pressure_unc_max, p_value_pressure_unc_max = calculate_z_test(mean_pressure_unc_max, mean_control_unc_max, se_pressure_unc_max)\n",
    "\n",
    "# Save unc_max results to a CSV\n",
    "unc_max_results = pd.DataFrame({\n",
    "    'Group': ['Control', 'Info', 'Pressure'],\n",
    "    'Mean': [mean_control_unc_max, mean_info_unc_max, mean_pressure_unc_max],\n",
    "    'Z-Score': [np.nan, z_score_info_unc_max, z_score_pressure_unc_max],\n",
    "    'P-Value': [np.nan, p_value_info_unc_max, p_value_pressure_unc_max]\n",
    "})\n",
    "unc_max_results.to_csv('unc_max_female_comparisons.csv', index=False)\n",
    "\n",
    "print(\"Results saved to CSV files for all analyses.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28638c72-4d6b-4656-9900-653fe1aa774e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b49d809e-9226-4ece-8eb0-7bfe42b75325",
   "metadata": {},
   "source": [
    "## Analysis depending on consumption outside the experiment\n",
    "\n",
    "Participants' level of comfort is likely to be affected by how frequently they consume pornography outside the experiments, so we examine separately by those groups here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f179bd2-b6d0-4dcf-9b01-a498be78b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z-Test Function\n",
    "def calculate_z_test(group1_mean, group2_mean, se):\n",
    "    z_score = (group1_mean - group2_mean) / se\n",
    "    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))\n",
    "    return z_score, p_value\n",
    "\n",
    "### 1. Split into low and high frequency for 'freq_porn'\n",
    "data_freq = data.dropna(subset=['freq_porn'])\n",
    "\n",
    "# Split into low and high frequency based on 'freq_porn'\n",
    "data_low_freq = data_freq[data_freq['freq_porn'] <= 2].copy()\n",
    "data_high_freq = data_freq[data_freq['freq_porn'] >= 3].copy()\n",
    "\n",
    "# Save the low and high frequency data to CSV\n",
    "data_low_freq.to_csv('low_freq_porn.csv', index=False)\n",
    "data_high_freq.to_csv('high_freq_porn.csv', index=False)\n",
    "\n",
    "### 2. Mean comparison for agg_mean (low freq_porn only)\n",
    "\n",
    "# Subset data by group_number for low freq_porn\n",
    "data_low_control = data_low_freq[data_low_freq['group_number'] == 'control'].dropna(subset=['agg_mean'])\n",
    "data_low_info = data_low_freq[data_low_freq['group_number'] == 'info'].dropna(subset=['agg_mean'])\n",
    "data_low_pressure = data_low_freq[data_low_freq['group_number'] == 'pressure'].dropna(subset=['agg_mean'])\n",
    "\n",
    "# Calculate means for agg_mean\n",
    "mean_control_agg = data_low_control['agg_mean'].mean()\n",
    "mean_info_agg = data_low_info['agg_mean'].mean()\n",
    "mean_pressure_agg = data_low_pressure['agg_mean'].mean()\n",
    "\n",
    "# Z-test between info and control groups\n",
    "se_info = data_low_info['agg_mean'].std() / np.sqrt(len(data_low_info))\n",
    "z_score_info, p_value_info = calculate_z_test(mean_info_agg, mean_control_agg, se_info)\n",
    "\n",
    "# Z-test between pressure and control groups\n",
    "se_pressure = data_low_pressure['agg_mean'].std() / np.sqrt(len(data_low_pressure))\n",
    "z_score_pressure, p_value_pressure = calculate_z_test(mean_pressure_agg, mean_control_agg, se_pressure)\n",
    "\n",
    "# Save agg_mean low freq_porn results to a CSV\n",
    "agg_mean_low_results = pd.DataFrame({\n",
    "    'Group': ['Control', 'Info', 'Pressure'],\n",
    "    'Mean': [mean_control_agg, mean_info_agg, mean_pressure_agg],\n",
    "    'Z-Score': [np.nan, z_score_info, z_score_pressure],\n",
    "    'P-Value': [np.nan, p_value_info, p_value_pressure]\n",
    "})\n",
    "agg_mean_low_results.to_csv('agg_mean_low_freq_porn_comparisons.csv', index=False)\n",
    "\n",
    "### 3. Mean comparison for unc_max (low freq_porn only)\n",
    "\n",
    "# Subset data for unc_max\n",
    "data_low_control_unc = data_low_control.dropna(subset=['unc_max'])\n",
    "data_low_info_unc = data_low_info.dropna(subset=['unc_max'])\n",
    "data_low_pressure_unc = data_low_pressure.dropna(subset=['unc_max'])\n",
    "\n",
    "# Calculate means for unc_max\n",
    "mean_control_unc = data_low_control_unc['unc_max'].mean()\n",
    "mean_info_unc = data_low_info_unc['unc_max'].mean()\n",
    "mean_pressure_unc = data_low_pressure_unc['unc_max'].mean()\n",
    "\n",
    "# Z-test for unc_max between info and control groups\n",
    "se_info_unc = data_low_info_unc['unc_max'].std() / np.sqrt(len(data_low_info_unc))\n",
    "z_score_info_unc, p_value_info_unc = calculate_z_test(mean_info_unc, mean_control_unc, se_info_unc)\n",
    "\n",
    "# Z-test for unc_max between pressure and control groups\n",
    "se_pressure_unc = data_low_pressure_unc['unc_max'].std() / np.sqrt(len(data_low_pressure_unc))\n",
    "z_score_pressure_unc, p_value_pressure_unc = calculate_z_test(mean_pressure_unc, mean_control_unc, se_pressure_unc)\n",
    "\n",
    "# Save unc_max low freq_porn results to a CSV\n",
    "unc_max_low_results = pd.DataFrame({\n",
    "    'Group': ['Control', 'Info', 'Pressure'],\n",
    "    'Mean': [mean_control_unc, mean_info_unc, mean_pressure_unc],\n",
    "    'Z-Score': [np.nan, z_score_info_unc, z_score_pressure_unc],\n",
    "    'P-Value': [np.nan, p_value_info_unc, p_value_pressure_unc]\n",
    "})\n",
    "unc_max_low_results.to_csv('unc_max_low_freq_porn_comparisons.csv', index=False)\n",
    "\n",
    "### 4. Mean comparison for agg_mean (high freq_porn only)\n",
    "\n",
    "# Subset data by group_number for high freq_porn\n",
    "data_high_control = data_high_freq[data_high_freq['group_number'] == 'control'].dropna(subset=['agg_mean'])\n",
    "data_high_info = data_high_freq[data_high_freq['group_number'] == 'info'].dropna(subset=['agg_mean'])\n",
    "data_high_pressure = data_high_freq[data_high_freq['group_number'] == 'pressure'].dropna(subset=['agg_mean'])\n",
    "\n",
    "# Calculate means for agg_mean\n",
    "mean_control_agg_high = data_high_control['agg_mean'].mean()\n",
    "mean_info_agg_high = data_high_info['agg_mean'].mean()\n",
    "mean_pressure_agg_high = data_high_pressure['agg_mean'].mean()\n",
    "\n",
    "# Z-test for agg_mean between info and control groups\n",
    "se_info_high = data_high_info['agg_mean'].std() / np.sqrt(len(data_high_info))\n",
    "z_score_info_high, p_value_info_high = calculate_z_test(mean_info_agg_high, mean_control_agg_high, se_info_high)\n",
    "\n",
    "# Z-test for agg_mean between pressure and control groups\n",
    "se_pressure_high = data_high_pressure['agg_mean'].std() / np.sqrt(len(data_high_pressure))\n",
    "z_score_pressure_high, p_value_pressure_high = calculate_z_test(mean_pressure_agg_high, mean_control_agg_high, se_pressure_high)\n",
    "\n",
    "# Save agg_mean high freq_porn results to a CSV\n",
    "agg_mean_high_results = pd.DataFrame({\n",
    "    'Group': ['Control', 'Info', 'Pressure'],\n",
    "    'Mean': [mean_control_agg_high, mean_info_agg_high, mean_pressure_agg_high],\n",
    "    'Z-Score': [np.nan, z_score_info_high, z_score_pressure_high],\n",
    "    'P-Value': [np.nan, p_value_info_high, p_value_pressure_high]\n",
    "})\n",
    "agg_mean_high_results.to_csv('agg_mean_high_freq_porn_comparisons.csv', index=False)\n",
    "\n",
    "### 5. Z-tests for con_mean and non_mean (high freq_porn only)\n",
    "\n",
    "# Subset data for con_mean (high frequency)\n",
    "data_high_control_con = data_high_control.dropna(subset=['con_mean'])\n",
    "data_high_info_con = data_high_info.dropna(subset=['con_mean'])\n",
    "data_high_pressure_con = data_high_pressure.dropna(subset=['con_mean'])\n",
    "\n",
    "# Z-test for con_mean between info and control groups\n",
    "se_info_con_high = data_high_info_con['con_mean'].std() / np.sqrt(len(data_high_info_con))\n",
    "z_score_info_con_high, p_value_info_con_high = calculate_z_test(data_high_info_con['con_mean'].mean(), data_high_control_con['con_mean'].mean(), se_info_con_high)\n",
    "\n",
    "# Z-test for con_mean between pressure and control groups\n",
    "se_pressure_con_high = data_high_pressure_con['con_mean'].std() / np.sqrt(len(data_high_pressure_con))\n",
    "z_score_pressure_con_high, p_value_pressure_con_high = calculate_z_test(data_high_pressure_con['con_mean'].mean(), data_high_control_con['con_mean'].mean(), se_pressure_con_high)\n",
    "\n",
    "# Save con_mean high freq_porn results to a CSV\n",
    "con_mean_high_results = pd.DataFrame({\n",
    "    'Group': ['Control', 'Info', 'Pressure'],\n",
    "    'Z-Score': [np.nan, z_score_info_con_high, z_score_pressure_con_high],\n",
    "    'P-Value': [np.nan, p_value_info_con_high, p_value_pressure_con_high]\n",
    "})\n",
    "con_mean_high_results.to_csv('con_mean_high_freq_porn_comparisons.csv', index=False)\n",
    "\n",
    "# Repeat similar Z-tests for non_mean and unc_max (high freq_porn)\n",
    "data_high_control_non = data_high_control.dropna(subset=['non_mean'])\n",
    "data_high_info_non = data_high_info.dropna(subset=['non_mean'])\n",
    "data_high_pressure_non = data_high_pressure.dropna(subset(['non_mean']))\n",
    "\n",
    "# Z-test for non_mean between info and control groups\n",
    "se_info_non_high = data_high_info_non['non_mean'].std() / np.sqrt(len(data_high_info_non))\n",
    "z_score_info_non_high, p_value_info_non_high = calculate_z_test(data_high_info_non['non_mean'].mean(), data_high_control_non['non_mean'].mean(), se_info_non_high)\n",
    "\n",
    "# Z-test for non_mean between pressure and control groups\n",
    "se_pressure_non_high = data_high_pressure_non['non_mean'].std() / np.sqrt(len(data_high_pressure_non))\n",
    "z_score_pressure_non_high, p_value_pressure_non_high = calculate_z_test(data_high_pressure_non['non_mean'].mean(), data_high_control_non['non_mean'].mean(), se_pressure_non_high)\n",
    "\n",
    "# Save non_mean high freq_porn results to a CSV\n",
    "non_mean_high_results = pd.DataFrame({\n",
    "    'Group': ['Control', 'Info', 'Pressure'],\n",
    "    'Z-Score': [np.nan, z_score_info_non_high, z_score_pressure_non_high],\n",
    "    'P-Value': [np.nan, p_value_info_non_high, p_value_pressure_non_high]\n",
    "})\n",
    "non_mean_high_results.to_csv('non_mean_high_freq_porn_comparisons.csv', index=False)\n",
    "\n",
    "### 6. Linear Regression Comparisons for agg_mean and freq_porn\n",
    "\n",
    "# Linear regression for control group\n",
    "regression_control = sm.OLS.from_formula('agg_mean ~ gender_identity + freq_porn', data=data_control).fit()\n",
    "with open('regression_control_summary.txt', 'w') as f:\n",
    "    f.write(regression_control.summary().as_text())\n",
    "\n",
    "# Linear regression for info group\n",
    "regression_info = sm.OLS.from_formula('agg_mean ~ gender_identity + freq_porn', data=data_info).fit()\n",
    "with open('regression_info_summary.txt', 'w') as f:\n",
    "    f.write(regression_info.summary().as_text())\n",
    "\n",
    "# Linear regression for pressure group\n",
    "regression_pressure = sm.OLS.from_formula('agg_mean ~ gender_identity + freq_porn', data=data_pressure).fit()\n",
    "with open('regression_pressure_summary.txt', 'w') as f:\n",
    "    f.write(regression_pressure.summary().as_text())\n",
    "\n",
    "print(\"All results saved to CSV and text files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e86fd6-8244-4347-92c1-f6e02fe90e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Linear regression to test if gender differences are fully explained by freq_porn\n",
    "model = ols('agg_mean ~ treatment + gender_identity + freq_porn', data=data).fit()\n",
    "\n",
    "# Save the model summary to a text file\n",
    "with open('linear_regression_gender_freq_porn_summary.txt', 'w') as f:\n",
    "    f.write(model.summary().as_text())\n",
    "\n",
    "# Test the significance of the gender coefficient after controlling for freq_porn\n",
    "model_controlled = ols('agg_mean ~ treatment + freq_porn + gender_identity:freq_porn', data=data).fit()\n",
    "anova_results = sm.stats.anova_lm(model, model_controlled)\n",
    "\n",
    "# Save ANOVA results to a CSV file\n",
    "anova_results.to_csv('anova_gender_freq_porn.csv')\n",
    "\n",
    "# 2. Linear regressions for male and female participants separately\n",
    "# For males\n",
    "model_male = ols('agg_mean ~ freq_porn', data=data_male).fit()\n",
    "with open('linear_regression_male_freq_porn_summary.txt', 'w') as f:\n",
    "    f.write(model_male.summary().as_text())\n",
    "\n",
    "# For females\n",
    "model_female = ols('agg_mean ~ freq_porn', data=data_female).fit()\n",
    "with open('linear_regression_female_freq_porn_summary.txt', 'w') as f:\n",
    "    f.write(model_female.summary().as_text())\n",
    "\n",
    "# 3. Double difference model: Interaction between guilt and treatment, for males and females\n",
    "\n",
    "# Create new 'guilt' and 'treat_yes' columns based on thresholds\n",
    "data_male['guilt'] = np.where(data_male['guilt_feelings'] <= 2, 0, 1)\n",
    "data_female['guilt'] = np.where(data_female['guilt_feelings'] <= 2, 0, 1)\n",
    "data_male['treat_yes'] = np.where((data_male['group_number'] == 'info') | (data_male['group_number'] == 'pressure'), 1, 0)\n",
    "data_female['treat_yes'] = np.where((data_female['group_number'] == 'info') | (data_female['group_number'] == 'pressure'), 1, 0)\n",
    "\n",
    "# Run linear regression models with interaction terms\n",
    "model_male_double = ols('agg_mean ~ treat_yes + guilt + treat_yes*guilt', data=data_male).fit()\n",
    "with open('double_diff_male_summary.txt', 'w') as f:\n",
    "    f.write(model_male_double.summary().as_text())\n",
    "\n",
    "model_female_double = ols('agg_mean ~ treat_yes + guilt + treat_yes*guilt', data=data_female).fit()\n",
    "with open('double_diff_female_summary.txt', 'w') as f:\n",
    "    f.write(model_female_double.summary().as_text())\n",
    "\n",
    "# 4. Interaction between guilt and group_number for men\n",
    "model_male_guilt_group = ols('agg_mean ~ guilt * group_number', data=data_male).fit()\n",
    "with open('interaction_guilt_group_male_summary.txt', 'w') as f:\n",
    "    f.write(model_male_guilt_group.summary().as_text())\n",
    "\n",
    "# 5. Triple difference model to test interactions between guilt, treatment, and gender\n",
    "data['guilt'] = np.where(data['guilt_feelings'] <= 2, 0, 1)\n",
    "data['treat_yes'] = np.where((data['group_number'] == 'info') | (data['group_number'] == 'pressure'), 1, 0)\n",
    "\n",
    "# Linear regression model with triple interaction terms\n",
    "model_triple_diff = ols('agg_mean ~ guilt + treat_yes + guilt*treat_yes + gender_identity + gender_identity*treat_yes + treat_yes*guilt*gender_identity', data=data).fit()\n",
    "with open('triple_diff_summary.txt', 'w') as f:\n",
    "    f.write(model_triple_diff.summary().as_text())\n",
    "\n",
    "# 6. Correlation between freq_porn and comfort with non-consensual scenarios\n",
    "non_mean_correlation = data[['non_mean', 'freq_porn']].corr().loc['non_mean', 'freq_porn']\n",
    "unc_max_correlation = data[['unc_max', 'freq_porn']].corr().loc['unc_max', 'freq_porn']\n",
    "\n",
    "# Save correlation results to a CSV file\n",
    "correlation_results = pd.DataFrame({\n",
    "    'Variable': ['non_mean', 'unc_max'],\n",
    "    'Correlation with freq_porn': [non_mean_correlation, unc_max_correlation]\n",
    "})\n",
    "correlation_results.to_csv('freq_porn_correlations.csv', index=False)\n",
    "\n",
    "print(\"All results saved to CSV and text files.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
